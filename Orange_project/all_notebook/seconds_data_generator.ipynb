{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining Feather Files: 100%|██████████| 361/361 [00:00<00:00, 7120.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, base_url, zip_download_dir, csv_extract_dir, feather_stored_dir):\n",
    "        self.base_url = base_url\n",
    "        self.zip_download_dir = zip_download_dir\n",
    "        self.csv_extract_dir = csv_extract_dir\n",
    "        self.feather_stored_dir = feather_stored_dir\n",
    "\n",
    "    def download_file(self, url, destination):\n",
    "        if os.path.exists(destination):\n",
    "            print(f\"File {destination} already exists. Skipping download.\")\n",
    "            return\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(destination, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "    def download_and_extract_and_feather_data(self, start_date, end_date):\n",
    "        os.makedirs(self.zip_download_dir, exist_ok=True)\n",
    "        os.makedirs(self.csv_extract_dir, exist_ok=True)\n",
    "        os.makedirs(self.feather_stored_dir, exist_ok=True)\n",
    "        download_bar = tqdm(total=(end_date - start_date).days + 1, desc=\"Downloading, Extracting, and Featherizing\")\n",
    "\n",
    "        for current_date in (start_date + datetime.timedelta(n) for n in range((end_date - start_date).days + 1)):\n",
    "            date_str = current_date.strftime('%Y-%m-%d')\n",
    "            zip_url = f'{self.base_url}ETHUSDT-aggTrades-{date_str}.zip'\n",
    "            zip_filename = os.path.join(self.zip_download_dir, f'ETHUSDT-aggTrades-{date_str}.zip')\n",
    "\n",
    "            self.download_file(zip_url, zip_filename)\n",
    "\n",
    "            with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "                for file_info in zip_ref.infolist():\n",
    "                    extracted_file_path = os.path.join(self.csv_extract_dir, file_info.filename)\n",
    "\n",
    "                    if not os.path.exists(extracted_file_path):\n",
    "                        zip_ref.extract(file_info, path=self.csv_extract_dir)\n",
    "                    else:\n",
    "                        print(f\"File {extracted_file_path} already exists. Skipping extraction.\")\n",
    "\n",
    "                    # Transfer to Feather format\n",
    "                    csv_file_path = extracted_file_path\n",
    "                    feather_file_path = os.path.join(self.feather_stored_dir, f\"{os.path.splitext(file_info.filename)[0]}.feather\")\n",
    "                    self.transfer_to_feather(csv_file_path, feather_file_path)\n",
    "\n",
    "            download_bar.update(1)\n",
    "        download_bar.close()\n",
    "\n",
    "    def transfer_to_feather(self, csv_file_path, feather_file_path):\n",
    "        if not os.path.exists(feather_file_path):\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            df = self._convert_to_seconds(df)\n",
    "            df.to_feather(feather_file_path)\n",
    "        else:\n",
    "            print(f\"Feather file for {csv_file_path} already exists. Skipping transfer.\")\n",
    "\n",
    "    def _convert_to_seconds(self, df):\n",
    "        df['utc_time'] = pd.to_datetime(df['transact_time'], unit='ms')\n",
    "        df.set_index('utc_time', inplace=True)\n",
    "\n",
    "        resampled_df = df.resample('S').agg({\n",
    "            'agg_trade_id': 'first',\n",
    "            'price': 'ohlc',\n",
    "            'quantity': 'sum',\n",
    "            'first_trade_id': 'first',\n",
    "            'last_trade_id': 'last',\n",
    "            'is_buyer_maker': 'last',\n",
    "        })\n",
    "        resampled_df.reset_index(inplace=True)\n",
    "        resampled_df.columns = resampled_df.columns.droplevel()\n",
    "        resampled_df.fillna(method='ffill', inplace=True)\n",
    "        resampled_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "        return resampled_df\n",
    "\n",
    "    def combine_from_feather_to_df(self, data_dir, start_date, end_date):\n",
    "        data_files = [file for file in os.listdir(data_dir) if file.endswith('.feather')]\n",
    "        data_files.sort()\n",
    "        combined_df = None\n",
    "        progress_bar = tqdm(total=len(data_files), desc=\"Combining Feather Files\")\n",
    "\n",
    "        for data_file in data_files:\n",
    "            date_str = '-'.join(data_file.split('-')[-3:]).replace('.feather', '')\n",
    "            file_date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "\n",
    "            if start_date <= file_date <= end_date:\n",
    "                data_path = os.path.join(data_dir, data_file)\n",
    "                df = pd.read_feather(data_path)\n",
    "                # df = self._convert_to_seconds(df)\n",
    "                combined_df = pd.concat([combined_df, df]) if combined_df is not None else df\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        progress_bar.close()\n",
    "        return combined_df\n",
    "\n",
    "    def delete_all_data(self):\n",
    "        os.system(f'rm -rf {self.zip_download_dir}')\n",
    "        os.system(f'rm -rf {self.csv_extract_dir}')\n",
    "        os.system(f'rm -rf {self.feather_stored_dir}')\n",
    "\n",
    "# Example usage:\n",
    "base_url = 'https://data.binance.vision/data/futures/um/daily/aggTrades/ETHUSDT/'\n",
    "zip_download_dir = '/allah/freqtrade/Orange_project/aggTrades/binance_aggTrades'\n",
    "csv_extract_dir = '/allah/freqtrade/Orange_project/aggTrades/decompressed_csv'\n",
    "feather_stored_dir = '/allah/freqtrade/Orange_project/aggTrades/feather_data'\n",
    "\n",
    "data_processor = DataProcessor(base_url, zip_download_dir, csv_extract_dir, feather_stored_dir)\n",
    "start_date = datetime.date(2023, 1, 1)\n",
    "end_date = datetime.date(2023, 10, 16)\n",
    "\n",
    "# Download, extract, and featherize data\n",
    "# data_processor.download_and_extract_and_feather_data(start_date, end_date)\n",
    "\n",
    "# # Combine selected Feather files to a DataFrame\n",
    "combined_df = data_processor.combine_from_feather_to_df(feather_stored_dir, datetime.date(2023, 10, 14), datetime.date(2023, 10, 15))\n",
    "\n",
    "# # Perform operations with combined_df as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import feather\n",
    "\n",
    "# combined_df = data_processor.combine_from_feather_to_df(feather_stored_dir, datetime.date(2023, 10, 13), datetime.date(2023, 10, 14))\n",
    "\n",
    "def format_and_save_dataframe(input_df, output_path):\n",
    "    # Create a copy of the input DataFrame\n",
    "    df_formatted = input_df.copy()\n",
    "\n",
    "    # Define the end time for your time series\n",
    "    end_time = datetime.strptime('2023-10-16 23:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Create a new index based on a range with 1-minute frequency\n",
    "    new_index = pd.date_range(end=end_time, periods=len(df_formatted), freq='1T')\n",
    "\n",
    "    # Assign the new index to the DataFrame and rename columns\n",
    "    df_formatted.index = new_index\n",
    "    df_formatted = df_formatted.rename(columns={'': 'real_1s'})\n",
    "\n",
    "    # Reset the index to make the 'date' column a regular column\n",
    "    df_formatted = df_formatted.reset_index()\n",
    "\n",
    "    # Rename and format columns to match the target format\n",
    "    df_formatted['date'] = df_formatted['index']\n",
    "    df_formatted['volume'] = df_formatted['quantity']\n",
    "    # df_formatted['date'] = pd.to_datetime(df_formatted['date']).dt.strftime('%Y-%m-%d %H:%M:%S') + '+00:00'\n",
    "    df_formatted['date'] = pd.to_datetime(df_formatted['date'])\n",
    "\n",
    "    df_formatted_temp = df_formatted[['date','real_1s','open', 'high', 'low', 'close', 'volume', 'first_trade_id', 'last_trade_id', 'agg_trade_id', 'is_buyer_maker']]\n",
    "\n",
    "    df_formatted = df_formatted[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "    # Save the formatted DataFrame to a Feather file\n",
    "    # feather.write_dataframe(df_formatted, output_path)\n",
    "    df_formatted.to_feather(\n",
    "            output_path, compression_level=9, compression='lz4')\n",
    "    return df_formatted_temp\n",
    "# Usage\n",
    "# input_df = combined_df.copy()  # Replace with your actual DataFrame\n",
    "output_path = '/allah/freqtrade/user_data/data/binance/futures/BTC_USDT_USDT-1m-futures.feather'\n",
    "df_formatted_temp = format_and_save_dataframe(combined_df, output_path)\n",
    "df_formatted_temp[['real_1s']].to_feather('/allah/freqtrade/user_data/strategies/real_1s.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataFrameProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def prepare_dataframe(self):\n",
    "        df_copy = self.df.copy()\n",
    "        df_copy.drop(\"date\", axis=1, inplace=True)\n",
    "        df_copy['real_1s'] = pd.to_datetime(df_copy['real_1s'])\n",
    "        df_copy = df_copy.sort_values(by='real_1s')\n",
    "        return df_copy\n",
    "\n",
    "    def calculate_aggregated_sum(self, df):\n",
    "        return df['volume'].cumsum()\n",
    "\n",
    "    def aggregate_minute_data(self):\n",
    "        aggregated_data = self.df.groupby(self.df['real_1s'].dt.strftime('%Y-%m-%d %H:%M')).apply(self.calculate_aggregated_sum)\n",
    "        return aggregated_data\n",
    "\n",
    "    def calculate_volumes_and_open_sum(self, df):\n",
    "        return pd.Series({\n",
    "            'current_minute_volume': df['volume'].sum(),\n",
    "            'open_price': df['open'].iloc[0]\n",
    "        })\n",
    "\n",
    "    def process_data(self):\n",
    "        df_test = self.prepare_dataframe()\n",
    "        df_test['aggregate_volume_sum'] = df_test.groupby(df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M')).apply(self.calculate_aggregated_sum).values\n",
    "        df_1m_aggregated = df_test.groupby(df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M')).apply(self.calculate_volumes_and_open_sum)\n",
    "        df_1m_aggregated = df_1m_aggregated.reset_index()\n",
    "        df_1m_aggregated.columns = ['real_1s', 'current_minute_volume', 'open_price']\n",
    "        df_1m_aggregated['last_5_minutes_volumes_sum'] = df_1m_aggregated['current_minute_volume'].rolling(6).sum() - df_1m_aggregated['current_minute_volume']\n",
    "        df_test['last_5_minutes_volumes_sum'] = df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M').map(df_1m_aggregated.set_index('real_1s')['last_5_minutes_volumes_sum'])\n",
    "        df_test['open_price'] = df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M').map(df_1m_aggregated.set_index('real_1s')['open_price'])\n",
    "        df_test['entry'] = 0\n",
    "        condition = df_test['aggregate_volume_sum'] > df_test['last_5_minutes_volumes_sum']\n",
    "        condition = condition & (condition != condition.shift(1))\n",
    "        df_test.loc[condition, 'entry'] = 1\n",
    "        return df_test\n",
    "\n",
    "# Usage\n",
    "df_processor = DataFrameProcessor(df_formatted_temp)\n",
    "df_processed = df_processor.process_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_1s</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>first_trade_id</th>\n",
       "      <th>last_trade_id</th>\n",
       "      <th>agg_trade_id</th>\n",
       "      <th>is_buyer_maker</th>\n",
       "      <th>aggregate_volume_sum</th>\n",
       "      <th>last_5_minutes_volumes_sum</th>\n",
       "      <th>open_price</th>\n",
       "      <th>entry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-14 00:00:00</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0.303</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>1.378952e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-14 00:00:01</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>1.378952e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-14 00:00:02</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>1.378952e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-14 00:00:03</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>1.378952e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-14 00:00:04</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>1606.71</td>\n",
       "      <td>1606.55</td>\n",
       "      <td>1606.55</td>\n",
       "      <td>376.870</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>3.227961e+09</td>\n",
       "      <td>1.378952e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>377.216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1606.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172791</th>\n",
       "      <td>2023-09-15 23:59:55</td>\n",
       "      <td>1640.74</td>\n",
       "      <td>1640.74</td>\n",
       "      <td>1640.74</td>\n",
       "      <td>1640.74</td>\n",
       "      <td>0.014</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>1.379998e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>741.170</td>\n",
       "      <td>4495.839</td>\n",
       "      <td>1640.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172792</th>\n",
       "      <td>2023-09-15 23:59:56</td>\n",
       "      <td>1640.73</td>\n",
       "      <td>1640.73</td>\n",
       "      <td>1640.56</td>\n",
       "      <td>1640.56</td>\n",
       "      <td>26.080</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>1.379998e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>767.250</td>\n",
       "      <td>4495.839</td>\n",
       "      <td>1640.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172793</th>\n",
       "      <td>2023-09-15 23:59:57</td>\n",
       "      <td>1640.57</td>\n",
       "      <td>1640.57</td>\n",
       "      <td>1640.56</td>\n",
       "      <td>1640.57</td>\n",
       "      <td>4.033</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>1.379998e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>771.283</td>\n",
       "      <td>4495.839</td>\n",
       "      <td>1640.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172794</th>\n",
       "      <td>2023-09-15 23:59:58</td>\n",
       "      <td>1640.57</td>\n",
       "      <td>1640.63</td>\n",
       "      <td>1640.57</td>\n",
       "      <td>1640.63</td>\n",
       "      <td>39.905</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>1.379998e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>811.188</td>\n",
       "      <td>4495.839</td>\n",
       "      <td>1640.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172795</th>\n",
       "      <td>2023-09-15 23:59:59</td>\n",
       "      <td>1640.64</td>\n",
       "      <td>1640.70</td>\n",
       "      <td>1640.64</td>\n",
       "      <td>1640.67</td>\n",
       "      <td>51.672</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>3.231375e+09</td>\n",
       "      <td>1.379998e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>862.860</td>\n",
       "      <td>4495.839</td>\n",
       "      <td>1640.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172796 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   real_1s     open     high      low    close   volume  \\\n",
       "0      2023-09-14 00:00:00  1606.69  1606.69  1606.69  1606.69    0.303   \n",
       "1      2023-09-14 00:00:01  1606.69  1606.69  1606.69  1606.69    0.000   \n",
       "2      2023-09-14 00:00:02  1606.69  1606.69  1606.69  1606.69    0.043   \n",
       "3      2023-09-14 00:00:03  1606.69  1606.69  1606.69  1606.69    0.000   \n",
       "4      2023-09-14 00:00:04  1606.69  1606.71  1606.55  1606.55  376.870   \n",
       "...                    ...      ...      ...      ...      ...      ...   \n",
       "172791 2023-09-15 23:59:55  1640.74  1640.74  1640.74  1640.74    0.014   \n",
       "172792 2023-09-15 23:59:56  1640.73  1640.73  1640.56  1640.56   26.080   \n",
       "172793 2023-09-15 23:59:57  1640.57  1640.57  1640.56  1640.57    4.033   \n",
       "172794 2023-09-15 23:59:58  1640.57  1640.63  1640.57  1640.63   39.905   \n",
       "172795 2023-09-15 23:59:59  1640.64  1640.70  1640.64  1640.67   51.672   \n",
       "\n",
       "        first_trade_id  last_trade_id  agg_trade_id  is_buyer_maker  \\\n",
       "0         3.227961e+09   3.227961e+09  1.378952e+09             0.0   \n",
       "1         3.227961e+09   3.227961e+09  1.378952e+09             0.0   \n",
       "2         3.227961e+09   3.227961e+09  1.378952e+09             0.0   \n",
       "3         3.227961e+09   3.227961e+09  1.378952e+09             0.0   \n",
       "4         3.227961e+09   3.227961e+09  1.378952e+09             1.0   \n",
       "...                ...            ...           ...             ...   \n",
       "172791    3.231375e+09   3.231375e+09  1.379998e+09             0.0   \n",
       "172792    3.231375e+09   3.231375e+09  1.379998e+09             1.0   \n",
       "172793    3.231375e+09   3.231375e+09  1.379998e+09             0.0   \n",
       "172794    3.231375e+09   3.231375e+09  1.379998e+09             0.0   \n",
       "172795    3.231375e+09   3.231375e+09  1.379998e+09             1.0   \n",
       "\n",
       "        aggregate_volume_sum  last_5_minutes_volumes_sum  open_price  entry  \n",
       "0                      0.303                         NaN     1606.69      0  \n",
       "1                      0.303                         NaN     1606.69      0  \n",
       "2                      0.346                         NaN     1606.69      0  \n",
       "3                      0.346                         NaN     1606.69      0  \n",
       "4                    377.216                         NaN     1606.69      0  \n",
       "...                      ...                         ...         ...    ...  \n",
       "172791               741.170                    4495.839     1640.45      0  \n",
       "172792               767.250                    4495.839     1640.45      0  \n",
       "172793               771.283                    4495.839     1640.45      0  \n",
       "172794               811.188                    4495.839     1640.45      0  \n",
       "172795               862.860                    4495.839     1640.45      0  \n",
       "\n",
       "[172796 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
