{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining Feather Files: 100%|██████████| 362/362 [00:00<00:00, 13020.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import feather\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, base_url, zip_download_dir, csv_extract_dir, feather_stored_dir):\n",
    "        self.base_url = base_url\n",
    "        self.zip_download_dir = zip_download_dir\n",
    "        self.csv_extract_dir = csv_extract_dir\n",
    "        self.feather_stored_dir = feather_stored_dir\n",
    "\n",
    "    def download_file(self, url, destination):\n",
    "        if os.path.exists(destination):\n",
    "            print(f\"File {destination} already exists. Skipping download.\")\n",
    "            return\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(destination, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "\n",
    "    def download_and_extract_and_feather_data(self, start_date, end_date):\n",
    "        os.makedirs(self.zip_download_dir, exist_ok=True)\n",
    "        os.makedirs(self.csv_extract_dir, exist_ok=True)\n",
    "        os.makedirs(self.feather_stored_dir, exist_ok=True)\n",
    "        download_bar = tqdm(total=(end_date - start_date).days + 1, desc=\"Downloading, Extracting, and Featherizing\")\n",
    "\n",
    "        for current_date in (start_date + datetime.timedelta(n) for n in range((end_date - start_date).days + 1)):\n",
    "            date_str = current_date.strftime('%Y-%m-%d')\n",
    "            zip_url = f'{self.base_url}ETHUSDT-aggTrades-{date_str}.zip'\n",
    "            zip_filename = os.path.join(self.zip_download_dir, f'ETHUSDT-aggTrades-{date_str}.zip')\n",
    "\n",
    "            self.download_file(zip_url, zip_filename)\n",
    "\n",
    "            with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "                for file_info in zip_ref.infolist():\n",
    "                    extracted_file_path = os.path.join(self.csv_extract_dir, file_info.filename)\n",
    "\n",
    "                    if not os.path.exists(extracted_file_path):\n",
    "                        zip_ref.extract(file_info, path=self.csv_extract_dir)\n",
    "                    else:\n",
    "                        print(f\"File {extracted_file_path} already exists. Skipping extraction.\")\n",
    "\n",
    "                    # Transfer to Feather format\n",
    "                    csv_file_path = extracted_file_path\n",
    "                    feather_file_path = os.path.join(self.feather_stored_dir, f\"{os.path.splitext(file_info.filename)[0]}.feather\")\n",
    "                    self.transfer_to_feather(csv_file_path, feather_file_path)\n",
    "\n",
    "            download_bar.update(1)\n",
    "        download_bar.close()\n",
    "\n",
    "    def transfer_to_feather(self, csv_file_path, feather_file_path):\n",
    "        if not os.path.exists(feather_file_path):\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            df = self._convert_to_seconds(df)\n",
    "            df.to_feather(feather_file_path)\n",
    "        else:\n",
    "            print(f\"Feather file for {csv_file_path} already exists. Skipping transfer.\")\n",
    "\n",
    "    def _convert_to_seconds(self, df):\n",
    "        df['utc_time'] = pd.to_datetime(df['transact_time'], unit='ms')\n",
    "        df.set_index('utc_time', inplace=True)\n",
    "\n",
    "        resampled_df = df.resample('S').agg({\n",
    "            'agg_trade_id': 'first',\n",
    "            'price': 'ohlc',\n",
    "            'quantity': 'sum',\n",
    "            'first_trade_id': 'first',\n",
    "            'last_trade_id': 'last',\n",
    "            'is_buyer_maker': 'last',\n",
    "        })\n",
    "        resampled_df.reset_index(inplace=True)\n",
    "        resampled_df.columns = resampled_df.columns.droplevel()\n",
    "        resampled_df.fillna(method='ffill', inplace=True)\n",
    "        resampled_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "        return resampled_df\n",
    "\n",
    "    def combine_from_feather_to_df(self, data_dir, start_date, end_date):\n",
    "        data_files = [file for file in os.listdir(data_dir) if file.endswith('.feather')]\n",
    "        data_files.sort()\n",
    "        combined_df = None\n",
    "        progress_bar = tqdm(total=len(data_files), desc=\"Combining Feather Files\")\n",
    "\n",
    "        for data_file in data_files:\n",
    "            date_str = '-'.join(data_file.split('-')[-3:]).replace('.feather', '')\n",
    "            file_date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "\n",
    "            if start_date <= file_date <= end_date:\n",
    "                data_path = os.path.join(data_dir, data_file)\n",
    "                df = pd.read_feather(data_path)\n",
    "                # df = self._convert_to_seconds(df)\n",
    "                combined_df = pd.concat([combined_df, df]) if combined_df is not None else df\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        progress_bar.close()\n",
    "        return combined_df\n",
    "\n",
    "    def delete_all_data(self):\n",
    "        os.system(f'rm -rf {self.zip_download_dir}')\n",
    "        os.system(f'rm -rf {self.csv_extract_dir}')\n",
    "        os.system(f'rm -rf {self.feather_stored_dir}')\n",
    "\n",
    "# Example usage:\n",
    "base_url = 'https://data.binance.vision/data/futures/um/daily/aggTrades/ETHUSDT/'\n",
    "zip_download_dir = '/allah/freqtrade/Orange_project/aggTrades/binance_aggTrades'\n",
    "csv_extract_dir = '/allah/freqtrade/Orange_project/aggTrades/decompressed_csv'\n",
    "feather_stored_dir = '/allah/freqtrade/Orange_project/aggTrades/feather_data'\n",
    "\n",
    "data_processor = DataProcessor(base_url, zip_download_dir, csv_extract_dir, feather_stored_dir)\n",
    "start_date = datetime.date(2023, 1, 1)\n",
    "end_date = datetime.date(2023, 10, 16)\n",
    "\n",
    "# Download, extract, and featherize data\n",
    "# data_processor.download_and_extract_and_feather_data(datetime.date(2023, 10, 1), datetime.date(2023, 10, 18))\n",
    "\n",
    "# # Combine selected Feather files to a DataFrame\n",
    "combined_df = data_processor.combine_from_feather_to_df(feather_stored_dir, datetime.date(2023, 10, 17), datetime.date(2023, 10, 18))\n",
    "\n",
    "# # Perform operations with combined_df as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import feather\n",
    "\n",
    "# combined_df = data_processor.combine_from_feather_to_df(feather_stored_dir, datetime.date(2023, 10, 13), datetime.date(2023, 10, 14))\n",
    "\n",
    "def format_and_save_dataframe(input_df, output_path):\n",
    "    # Create a copy of the input DataFrame\n",
    "    df_formatted = input_df.copy()\n",
    "\n",
    "    # Define the end time for your time series\n",
    "    end_time = datetime.strptime('2023-10-16 23:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Create a new index based on a range with 1-minute frequency\n",
    "    new_index = pd.date_range(end=end_time, periods=len(df_formatted), freq='1T')\n",
    "\n",
    "    # Assign the new index to the DataFrame and rename columns\n",
    "    df_formatted.index = new_index\n",
    "    df_formatted = df_formatted.rename(columns={'': 'real_1s'})\n",
    "\n",
    "    # Reset the index to make the 'date' column a regular column\n",
    "    df_formatted = df_formatted.reset_index()\n",
    "\n",
    "    # Rename and format columns to match the target format\n",
    "    df_formatted['date'] = df_formatted['index']\n",
    "    df_formatted['volume'] = df_formatted['quantity']\n",
    "    # df_formatted['date'] = pd.to_datetime(df_formatted['date']).dt.strftime('%Y-%m-%d %H:%M:%S') + '+00:00'\n",
    "    df_formatted['date'] = pd.to_datetime(df_formatted['date'])\n",
    "\n",
    "    df_formatted_temp = df_formatted[['date','real_1s','open', 'high', 'low', 'close', 'volume', 'first_trade_id', 'last_trade_id', 'agg_trade_id', 'is_buyer_maker']]\n",
    "\n",
    "    df_formatted = df_formatted[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "    # Save the formatted DataFrame to a Feather file\n",
    "    # feather.write_dataframe(df_formatted, output_path)\n",
    "    df_formatted.to_feather(\n",
    "            output_path, compression_level=9, compression='lz4')\n",
    "    return df_formatted_temp\n",
    "# Usage\n",
    "# input_df = combined_df.copy()  # Replace with your actual DataFrame\n",
    "output_path = '/allah/freqtrade/user_data/data/binance/futures/BTC_USDT_USDT-1m-futures.feather'\n",
    "df_formatted_temp = format_and_save_dataframe(combined_df, output_path)\n",
    "df_formatted_temp[['date','real_1s']].to_feather('/allah/freqtrade/user_data/strategies/real_1s.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DataFrameProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def prepare_dataframe(self):\n",
    "        df_copy = self.df.copy()\n",
    "        df_copy.drop(\"date\", axis=1, inplace=True)\n",
    "        df_copy['real_1s'] = pd.to_datetime(df_copy['real_1s'])\n",
    "        df_copy = df_copy.sort_values(by='real_1s')\n",
    "        return df_copy\n",
    "\n",
    "    def calculate_aggregated_sum(self, df):\n",
    "        return df['volume'].cumsum()\n",
    "\n",
    "    def aggregate_minute_data(self):\n",
    "        aggregated_data = self.df.groupby(self.df['real_1s'].dt.strftime('%Y-%m-%d %H:%M')).apply(self.calculate_aggregated_sum)\n",
    "        return aggregated_data\n",
    "\n",
    "    def calculate_volumes_and_open_sum(self, df):\n",
    "        return pd.Series({\n",
    "            'current_minute_volume': df['volume'].sum(),\n",
    "            'open_price': df['open'].iloc[0]\n",
    "        })\n",
    "\n",
    "    def process_data(self):\n",
    "        df_test = self.prepare_dataframe()\n",
    "        df_test['aggregate_volume_sum'] = df_test.groupby(df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M')).apply(self.calculate_aggregated_sum).values\n",
    "        df_1m_aggregated = df_test.groupby(df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M')).apply(self.calculate_volumes_and_open_sum)\n",
    "        df_1m_aggregated = df_1m_aggregated.reset_index()\n",
    "        df_1m_aggregated.columns = ['real_1s', 'current_minute_volume', 'open_price']\n",
    "        df_1m_aggregated['last_5_minutes_volumes_sum'] = df_1m_aggregated['current_minute_volume'].rolling(6).sum() - df_1m_aggregated['current_minute_volume']\n",
    "        df_test['last_5_minutes_volumes_sum'] = df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M').map(df_1m_aggregated.set_index('real_1s')['last_5_minutes_volumes_sum'])\n",
    "        df_test['open_price'] = df_test['real_1s'].dt.strftime('%Y-%m-%d %H:%M').map(df_1m_aggregated.set_index('real_1s')['open_price'])\n",
    "        df_test['entry'] = 0\n",
    "        condition = df_test['aggregate_volume_sum'] > df_test['last_5_minutes_volumes_sum']\n",
    "        condition = condition & (condition != condition.shift(1))\n",
    "        df_test.loc[condition, 'entry'] = 1\n",
    "        return df_test\n",
    "\n",
    "# Usage\n",
    "df_processor = DataFrameProcessor(df_formatted_temp)\n",
    "df_processed = df_processor.process_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
