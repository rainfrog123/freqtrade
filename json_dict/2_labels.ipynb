{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_short = pd.read_json('/allah/freqtrade/json_dict/2023-09-06_17-41-16_MacdStrategyShort.json')\n",
    "# df_long = pd.read_json('/allah/freqtrade/json_dict/2023-09-10_14-30-20_MacdStrategyLong.json')\n",
    "# df_long = pd.read_json('/allah/freqtrade/json_dict/2023-09-06_18-00-38_MacdStrategyLong.json')\n",
    "df_combined = pd.read_json('/allah/freqtrade/json_dict/2023-09-10_16-54-32_MacdStrategyCombined.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 30 Volume Version \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "lag_features = ['volume']  # List of features to create lag columns for\n",
    "lag_columns = []  # List to store the names of generated lag columns\n",
    "\n",
    "for feature in lag_features:\n",
    "    for i in range(1, 21):\n",
    "        df_combined[f'{feature}_{i}'] = df_combined[feature].shift(i)\n",
    "        # Append the generated lag column names to the lag_columns list\n",
    "        lag_columns.append(f'{feature}_{i}')\n",
    "\n",
    "# Now, lag_columns contains the names of all generated lag columns\n",
    "# df_long['macd_direction'] = np.where(df_long.macdhist > 0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({0: 16434, 1: 5197})\n",
      "Class distribution after oversampling: Counter({1: 16434, 0: 16434})\n",
      "X_train shape: (21631, 20)\n",
      "y_train shape: (21631,)\n",
      "Epoch 1/5000\n",
      "1028/1028 [==============================] - 2s 1ms/step - loss: 0.6801 - accuracy: 0.5658 - val_loss: 0.6747 - val_accuracy: 0.5412\n",
      "Epoch 2/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6764 - accuracy: 0.5740 - val_loss: 0.6776 - val_accuracy: 0.5322\n",
      "Epoch 3/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6751 - accuracy: 0.5716 - val_loss: 0.6872 - val_accuracy: 0.5085\n",
      "Epoch 4/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.5728 - val_loss: 0.6986 - val_accuracy: 0.4821\n",
      "Epoch 5/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6738 - accuracy: 0.5737 - val_loss: 0.7025 - val_accuracy: 0.4713\n",
      "Epoch 6/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6736 - accuracy: 0.5737 - val_loss: 0.6917 - val_accuracy: 0.5059\n",
      "Epoch 7/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6731 - accuracy: 0.5754 - val_loss: 0.6840 - val_accuracy: 0.5189\n",
      "Epoch 8/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6727 - accuracy: 0.5744 - val_loss: 0.7046 - val_accuracy: 0.4710\n",
      "Epoch 9/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6721 - accuracy: 0.5747 - val_loss: 0.6948 - val_accuracy: 0.4932\n",
      "Epoch 10/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6719 - accuracy: 0.5778 - val_loss: 0.6985 - val_accuracy: 0.4922\n",
      "Epoch 11/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6714 - accuracy: 0.5775 - val_loss: 0.6960 - val_accuracy: 0.4941\n",
      "Epoch 12/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6710 - accuracy: 0.5776 - val_loss: 0.6956 - val_accuracy: 0.4998\n",
      "Epoch 13/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6704 - accuracy: 0.5768 - val_loss: 0.6872 - val_accuracy: 0.5220\n",
      "Epoch 14/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6696 - accuracy: 0.5804 - val_loss: 0.7121 - val_accuracy: 0.4699\n",
      "Epoch 15/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6686 - accuracy: 0.5811 - val_loss: 0.6833 - val_accuracy: 0.5370\n",
      "Epoch 16/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6676 - accuracy: 0.5824 - val_loss: 0.7005 - val_accuracy: 0.5037\n",
      "Epoch 17/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6664 - accuracy: 0.5851 - val_loss: 0.6744 - val_accuracy: 0.5684\n",
      "Epoch 18/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6659 - accuracy: 0.5827 - val_loss: 0.6966 - val_accuracy: 0.5165\n",
      "Epoch 19/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.5880 - val_loss: 0.7210 - val_accuracy: 0.4584\n",
      "Epoch 20/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6632 - accuracy: 0.5891 - val_loss: 0.6835 - val_accuracy: 0.5475\n",
      "Epoch 21/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6624 - accuracy: 0.5893 - val_loss: 0.7165 - val_accuracy: 0.4835\n",
      "Epoch 22/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6615 - accuracy: 0.5922 - val_loss: 0.7194 - val_accuracy: 0.4732\n",
      "Epoch 23/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6602 - accuracy: 0.5930 - val_loss: 0.7081 - val_accuracy: 0.5024\n",
      "Epoch 24/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6589 - accuracy: 0.5973 - val_loss: 0.6995 - val_accuracy: 0.5159\n",
      "Epoch 25/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6578 - accuracy: 0.5958 - val_loss: 0.6874 - val_accuracy: 0.5699\n",
      "Epoch 26/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6576 - accuracy: 0.5959 - val_loss: 0.7037 - val_accuracy: 0.5070\n",
      "Epoch 27/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6558 - accuracy: 0.5987 - val_loss: 0.7229 - val_accuracy: 0.4874\n",
      "Epoch 28/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6546 - accuracy: 0.5997 - val_loss: 0.7220 - val_accuracy: 0.4982\n",
      "Epoch 29/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6535 - accuracy: 0.6015 - val_loss: 0.7328 - val_accuracy: 0.4663\n",
      "Epoch 30/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6527 - accuracy: 0.6012 - val_loss: 0.7066 - val_accuracy: 0.5050\n",
      "Epoch 31/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6518 - accuracy: 0.6032 - val_loss: 0.7061 - val_accuracy: 0.5320\n",
      "Epoch 32/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6508 - accuracy: 0.6043 - val_loss: 0.7163 - val_accuracy: 0.5018\n",
      "Epoch 33/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6500 - accuracy: 0.6061 - val_loss: 0.7157 - val_accuracy: 0.4815\n",
      "Epoch 34/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6479 - accuracy: 0.6054 - val_loss: 0.7194 - val_accuracy: 0.5092\n",
      "Epoch 35/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6474 - accuracy: 0.6090 - val_loss: 0.7114 - val_accuracy: 0.5325\n",
      "Epoch 36/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6462 - accuracy: 0.6108 - val_loss: 0.7285 - val_accuracy: 0.4945\n",
      "Epoch 37/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6452 - accuracy: 0.6083 - val_loss: 0.7003 - val_accuracy: 0.5564\n",
      "Epoch 38/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6452 - accuracy: 0.6104 - val_loss: 0.7280 - val_accuracy: 0.5137\n",
      "Epoch 39/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6438 - accuracy: 0.6124 - val_loss: 0.7391 - val_accuracy: 0.4889\n",
      "Epoch 40/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6424 - accuracy: 0.6141 - val_loss: 0.7543 - val_accuracy: 0.4658\n",
      "Epoch 41/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6409 - accuracy: 0.6172 - val_loss: 0.7376 - val_accuracy: 0.5067\n",
      "Epoch 42/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6402 - accuracy: 0.6141 - val_loss: 0.7308 - val_accuracy: 0.5279\n",
      "Epoch 43/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6390 - accuracy: 0.6149 - val_loss: 0.7524 - val_accuracy: 0.4678\n",
      "Epoch 44/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6376 - accuracy: 0.6186 - val_loss: 0.7409 - val_accuracy: 0.5002\n",
      "Epoch 45/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6380 - accuracy: 0.6170 - val_loss: 0.7347 - val_accuracy: 0.5268\n",
      "Epoch 46/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6364 - accuracy: 0.6199 - val_loss: 0.7474 - val_accuracy: 0.5083\n",
      "Epoch 47/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6353 - accuracy: 0.6210 - val_loss: 0.7442 - val_accuracy: 0.4856\n",
      "Epoch 48/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6337 - accuracy: 0.6238 - val_loss: 0.7579 - val_accuracy: 0.4706\n",
      "Epoch 49/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6331 - accuracy: 0.6251 - val_loss: 0.7774 - val_accuracy: 0.4565\n",
      "Epoch 50/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6316 - accuracy: 0.6271 - val_loss: 0.7789 - val_accuracy: 0.4488\n",
      "Epoch 51/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6313 - accuracy: 0.6251 - val_loss: 0.7703 - val_accuracy: 0.4985\n",
      "Epoch 52/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6301 - accuracy: 0.6245 - val_loss: 0.7399 - val_accuracy: 0.5272\n",
      "Epoch 53/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6288 - accuracy: 0.6268 - val_loss: 0.7814 - val_accuracy: 0.5050\n",
      "Epoch 54/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6286 - accuracy: 0.6264 - val_loss: 0.7835 - val_accuracy: 0.5050\n",
      "Epoch 55/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6278 - accuracy: 0.6280 - val_loss: 0.7651 - val_accuracy: 0.5044\n",
      "Epoch 56/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6267 - accuracy: 0.6289 - val_loss: 0.7726 - val_accuracy: 0.5329\n",
      "Epoch 57/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6260 - accuracy: 0.6298 - val_loss: 0.7774 - val_accuracy: 0.5148\n",
      "Epoch 58/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6245 - accuracy: 0.6309 - val_loss: 0.7845 - val_accuracy: 0.4861\n",
      "Epoch 59/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6247 - accuracy: 0.6320 - val_loss: 0.7692 - val_accuracy: 0.5649\n",
      "Epoch 60/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6237 - accuracy: 0.6313 - val_loss: 0.7785 - val_accuracy: 0.4789\n",
      "Epoch 61/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6217 - accuracy: 0.6340 - val_loss: 0.7933 - val_accuracy: 0.4904\n",
      "Epoch 62/5000\n",
      "1028/1028 [==============================] - 36s 36ms/step - loss: 0.6205 - accuracy: 0.6341 - val_loss: 0.8179 - val_accuracy: 0.4826\n",
      "Epoch 63/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6203 - accuracy: 0.6334 - val_loss: 0.8172 - val_accuracy: 0.5120\n",
      "Epoch 64/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6208 - accuracy: 0.6335 - val_loss: 0.7803 - val_accuracy: 0.5105\n",
      "Epoch 65/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6193 - accuracy: 0.6375 - val_loss: 0.8154 - val_accuracy: 0.5266\n",
      "Epoch 66/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6193 - accuracy: 0.6375 - val_loss: 0.8277 - val_accuracy: 0.4830\n",
      "Epoch 67/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6177 - accuracy: 0.6370 - val_loss: 0.7992 - val_accuracy: 0.5466\n",
      "Epoch 68/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6169 - accuracy: 0.6379 - val_loss: 0.8421 - val_accuracy: 0.5298\n",
      "Epoch 69/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6160 - accuracy: 0.6381 - val_loss: 0.8181 - val_accuracy: 0.5039\n",
      "Epoch 70/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6164 - accuracy: 0.6365 - val_loss: 0.8053 - val_accuracy: 0.5144\n",
      "Epoch 71/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6138 - accuracy: 0.6401 - val_loss: 0.8180 - val_accuracy: 0.5403\n",
      "Epoch 72/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6132 - accuracy: 0.6419 - val_loss: 0.8120 - val_accuracy: 0.5266\n",
      "Epoch 73/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6129 - accuracy: 0.6416 - val_loss: 0.8123 - val_accuracy: 0.5285\n",
      "Epoch 74/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6132 - accuracy: 0.6424 - val_loss: 0.8470 - val_accuracy: 0.5172\n",
      "Epoch 75/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6111 - accuracy: 0.6444 - val_loss: 0.8322 - val_accuracy: 0.5015\n",
      "Epoch 76/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6105 - accuracy: 0.6424 - val_loss: 0.8682 - val_accuracy: 0.4778\n",
      "Epoch 77/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6117 - accuracy: 0.6413 - val_loss: 0.8239 - val_accuracy: 0.5007\n",
      "Epoch 78/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6099 - accuracy: 0.6453 - val_loss: 0.8355 - val_accuracy: 0.5185\n",
      "Epoch 79/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6093 - accuracy: 0.6445 - val_loss: 0.8569 - val_accuracy: 0.5311\n",
      "Epoch 80/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6087 - accuracy: 0.6446 - val_loss: 0.8615 - val_accuracy: 0.4747\n",
      "Epoch 81/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6077 - accuracy: 0.6469 - val_loss: 0.8786 - val_accuracy: 0.5022\n",
      "Epoch 82/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6083 - accuracy: 0.6445 - val_loss: 0.8817 - val_accuracy: 0.4865\n",
      "Epoch 83/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6062 - accuracy: 0.6467 - val_loss: 0.8578 - val_accuracy: 0.4909\n",
      "Epoch 84/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6067 - accuracy: 0.6474 - val_loss: 0.8636 - val_accuracy: 0.5052\n",
      "Epoch 85/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6067 - accuracy: 0.6492 - val_loss: 0.8644 - val_accuracy: 0.5296\n",
      "Epoch 86/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6053 - accuracy: 0.6488 - val_loss: 0.8867 - val_accuracy: 0.5120\n",
      "Epoch 87/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6054 - accuracy: 0.6477 - val_loss: 0.9046 - val_accuracy: 0.4943\n",
      "Epoch 88/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6044 - accuracy: 0.6488 - val_loss: 0.8528 - val_accuracy: 0.5296\n",
      "Epoch 89/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6042 - accuracy: 0.6488 - val_loss: 0.8899 - val_accuracy: 0.4466\n",
      "Epoch 90/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6034 - accuracy: 0.6497 - val_loss: 0.8813 - val_accuracy: 0.5285\n",
      "Epoch 91/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6022 - accuracy: 0.6516 - val_loss: 0.8888 - val_accuracy: 0.5022\n",
      "Epoch 92/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6015 - accuracy: 0.6516 - val_loss: 0.8594 - val_accuracy: 0.5668\n",
      "Epoch 93/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6014 - accuracy: 0.6503 - val_loss: 0.8810 - val_accuracy: 0.5026\n",
      "Epoch 94/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6017 - accuracy: 0.6527 - val_loss: 0.8630 - val_accuracy: 0.5185\n",
      "Epoch 95/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6015 - accuracy: 0.6526 - val_loss: 0.8911 - val_accuracy: 0.5272\n",
      "Epoch 96/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.6003 - accuracy: 0.6526 - val_loss: 0.8766 - val_accuracy: 0.5107\n",
      "Epoch 97/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5997 - accuracy: 0.6533 - val_loss: 0.9184 - val_accuracy: 0.4893\n",
      "Epoch 98/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5997 - accuracy: 0.6553 - val_loss: 0.8888 - val_accuracy: 0.4793\n",
      "Epoch 99/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5979 - accuracy: 0.6540 - val_loss: 0.8798 - val_accuracy: 0.5218\n",
      "Epoch 100/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5983 - accuracy: 0.6546 - val_loss: 0.9120 - val_accuracy: 0.4763\n",
      "Epoch 101/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5981 - accuracy: 0.6541 - val_loss: 0.9181 - val_accuracy: 0.4778\n",
      "Epoch 102/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5982 - accuracy: 0.6543 - val_loss: 0.9109 - val_accuracy: 0.5065\n",
      "Epoch 103/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5971 - accuracy: 0.6549 - val_loss: 0.9153 - val_accuracy: 0.4863\n",
      "Epoch 104/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5968 - accuracy: 0.6559 - val_loss: 0.8686 - val_accuracy: 0.5307\n",
      "Epoch 105/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5957 - accuracy: 0.6555 - val_loss: 0.9466 - val_accuracy: 0.4747\n",
      "Epoch 106/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5961 - accuracy: 0.6548 - val_loss: 0.9427 - val_accuracy: 0.5089\n",
      "Epoch 107/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5950 - accuracy: 0.6556 - val_loss: 0.9158 - val_accuracy: 0.5383\n",
      "Epoch 108/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5953 - accuracy: 0.6574 - val_loss: 0.9304 - val_accuracy: 0.5046\n",
      "Epoch 109/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5949 - accuracy: 0.6564 - val_loss: 0.9702 - val_accuracy: 0.4767\n",
      "Epoch 110/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5943 - accuracy: 0.6558 - val_loss: 0.9152 - val_accuracy: 0.5116\n",
      "Epoch 111/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5931 - accuracy: 0.6572 - val_loss: 0.9441 - val_accuracy: 0.5453\n",
      "Epoch 112/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5932 - accuracy: 0.6569 - val_loss: 0.9676 - val_accuracy: 0.4889\n",
      "Epoch 113/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5925 - accuracy: 0.6587 - val_loss: 0.9559 - val_accuracy: 0.4584\n",
      "Epoch 114/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5917 - accuracy: 0.6581 - val_loss: 0.9233 - val_accuracy: 0.5076\n",
      "Epoch 115/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5917 - accuracy: 0.6611 - val_loss: 0.9373 - val_accuracy: 0.5231\n",
      "Epoch 116/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5905 - accuracy: 0.6606 - val_loss: 0.9513 - val_accuracy: 0.5235\n",
      "Epoch 117/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5902 - accuracy: 0.6587 - val_loss: 0.9592 - val_accuracy: 0.4830\n",
      "Epoch 118/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5902 - accuracy: 0.6598 - val_loss: 0.9746 - val_accuracy: 0.5320\n",
      "Epoch 119/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5910 - accuracy: 0.6598 - val_loss: 0.9943 - val_accuracy: 0.4835\n",
      "Epoch 120/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5900 - accuracy: 0.6574 - val_loss: 0.9795 - val_accuracy: 0.4922\n",
      "Epoch 121/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5891 - accuracy: 0.6616 - val_loss: 0.9774 - val_accuracy: 0.5281\n",
      "Epoch 122/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5879 - accuracy: 0.6635 - val_loss: 0.9609 - val_accuracy: 0.5353\n",
      "Epoch 123/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5890 - accuracy: 0.6613 - val_loss: 0.9581 - val_accuracy: 0.5050\n",
      "Epoch 124/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5881 - accuracy: 0.6614 - val_loss: 0.9910 - val_accuracy: 0.4778\n",
      "Epoch 125/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5876 - accuracy: 0.6612 - val_loss: 1.0098 - val_accuracy: 0.4924\n",
      "Epoch 126/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5861 - accuracy: 0.6630 - val_loss: 0.9832 - val_accuracy: 0.5067\n",
      "Epoch 127/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5874 - accuracy: 0.6621 - val_loss: 0.9606 - val_accuracy: 0.5035\n",
      "Epoch 128/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5866 - accuracy: 0.6638 - val_loss: 0.9882 - val_accuracy: 0.4628\n",
      "Epoch 129/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5851 - accuracy: 0.6656 - val_loss: 0.9948 - val_accuracy: 0.5272\n",
      "Epoch 130/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5857 - accuracy: 0.6615 - val_loss: 0.9946 - val_accuracy: 0.5189\n",
      "Epoch 131/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5846 - accuracy: 0.6656 - val_loss: 1.0193 - val_accuracy: 0.5178\n",
      "Epoch 132/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5843 - accuracy: 0.6653 - val_loss: 1.0578 - val_accuracy: 0.5141\n",
      "Epoch 133/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5847 - accuracy: 0.6648 - val_loss: 1.0292 - val_accuracy: 0.4834\n",
      "Epoch 134/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5846 - accuracy: 0.6650 - val_loss: 0.9883 - val_accuracy: 0.5322\n",
      "Epoch 135/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5823 - accuracy: 0.6659 - val_loss: 1.0493 - val_accuracy: 0.4915\n",
      "Epoch 136/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5830 - accuracy: 0.6658 - val_loss: 1.0121 - val_accuracy: 0.5520\n",
      "Epoch 137/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5820 - accuracy: 0.6661 - val_loss: 0.9894 - val_accuracy: 0.5059\n",
      "Epoch 138/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5818 - accuracy: 0.6660 - val_loss: 1.0524 - val_accuracy: 0.4952\n",
      "Epoch 139/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5818 - accuracy: 0.6665 - val_loss: 1.0226 - val_accuracy: 0.5447\n",
      "Epoch 140/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.6673 - val_loss: 1.0531 - val_accuracy: 0.4553\n",
      "Epoch 141/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.6676 - val_loss: 1.0737 - val_accuracy: 0.4893\n",
      "Epoch 142/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5813 - accuracy: 0.6675 - val_loss: 1.0076 - val_accuracy: 0.5534\n",
      "Epoch 143/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5812 - accuracy: 0.6655 - val_loss: 1.0337 - val_accuracy: 0.5337\n",
      "Epoch 144/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5805 - accuracy: 0.6662 - val_loss: 1.0280 - val_accuracy: 0.5298\n",
      "Epoch 145/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5794 - accuracy: 0.6675 - val_loss: 1.0333 - val_accuracy: 0.5100\n",
      "Epoch 146/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.6688 - val_loss: 0.9932 - val_accuracy: 0.5420\n",
      "Epoch 147/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5789 - accuracy: 0.6680 - val_loss: 1.0479 - val_accuracy: 0.5048\n",
      "Epoch 148/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5772 - accuracy: 0.6700 - val_loss: 1.0419 - val_accuracy: 0.4885\n",
      "Epoch 149/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5787 - accuracy: 0.6675 - val_loss: 1.0335 - val_accuracy: 0.5094\n",
      "Epoch 150/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5779 - accuracy: 0.6692 - val_loss: 1.0463 - val_accuracy: 0.5002\n",
      "Epoch 151/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5783 - accuracy: 0.6684 - val_loss: 1.1094 - val_accuracy: 0.5124\n",
      "Epoch 152/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5763 - accuracy: 0.6709 - val_loss: 1.1051 - val_accuracy: 0.5220\n",
      "Epoch 153/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5760 - accuracy: 0.6703 - val_loss: 1.1160 - val_accuracy: 0.5183\n",
      "Epoch 154/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5774 - accuracy: 0.6702 - val_loss: 1.0769 - val_accuracy: 0.5398\n",
      "Epoch 155/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5756 - accuracy: 0.6699 - val_loss: 1.0835 - val_accuracy: 0.5270\n",
      "Epoch 156/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.6717 - val_loss: 1.1146 - val_accuracy: 0.5050\n",
      "Epoch 157/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5762 - accuracy: 0.6700 - val_loss: 1.1036 - val_accuracy: 0.5590\n",
      "Epoch 158/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5752 - accuracy: 0.6704 - val_loss: 1.0366 - val_accuracy: 0.5246\n",
      "Epoch 159/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5757 - accuracy: 0.6720 - val_loss: 1.0797 - val_accuracy: 0.5055\n",
      "Epoch 160/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5747 - accuracy: 0.6715 - val_loss: 1.1319 - val_accuracy: 0.5814\n",
      "Epoch 161/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5739 - accuracy: 0.6727 - val_loss: 1.0761 - val_accuracy: 0.5150\n",
      "Epoch 162/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5738 - accuracy: 0.6734 - val_loss: 1.1105 - val_accuracy: 0.4965\n",
      "Epoch 163/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5714 - accuracy: 0.6735 - val_loss: 1.0980 - val_accuracy: 0.5207\n",
      "Epoch 164/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5725 - accuracy: 0.6735 - val_loss: 1.0776 - val_accuracy: 0.4965\n",
      "Epoch 165/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5713 - accuracy: 0.6737 - val_loss: 1.1153 - val_accuracy: 0.5113\n",
      "Epoch 166/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.6749 - val_loss: 1.1394 - val_accuracy: 0.5484\n",
      "Epoch 167/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5741 - accuracy: 0.6707 - val_loss: 1.0924 - val_accuracy: 0.5181\n",
      "Epoch 168/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5715 - accuracy: 0.6720 - val_loss: 1.0973 - val_accuracy: 0.5189\n",
      "Epoch 169/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5710 - accuracy: 0.6745 - val_loss: 1.1164 - val_accuracy: 0.4924\n",
      "Epoch 170/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5724 - accuracy: 0.6719 - val_loss: 1.1023 - val_accuracy: 0.5577\n",
      "Epoch 171/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5722 - accuracy: 0.6742 - val_loss: 1.0614 - val_accuracy: 0.5601\n",
      "Epoch 172/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5706 - accuracy: 0.6741 - val_loss: 1.1335 - val_accuracy: 0.5183\n",
      "Epoch 173/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5706 - accuracy: 0.6741 - val_loss: 1.1459 - val_accuracy: 0.5022\n",
      "Epoch 174/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5703 - accuracy: 0.6721 - val_loss: 1.0861 - val_accuracy: 0.5163\n",
      "Epoch 175/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.6764 - val_loss: 1.1071 - val_accuracy: 0.5246\n",
      "Epoch 176/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5688 - accuracy: 0.6756 - val_loss: 1.1543 - val_accuracy: 0.4989\n",
      "Epoch 177/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5704 - accuracy: 0.6727 - val_loss: 1.1678 - val_accuracy: 0.5133\n",
      "Epoch 178/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.6770 - val_loss: 1.1546 - val_accuracy: 0.5338\n",
      "Epoch 179/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5678 - accuracy: 0.6752 - val_loss: 1.1497 - val_accuracy: 0.5113\n",
      "Epoch 180/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5684 - accuracy: 0.6746 - val_loss: 1.1468 - val_accuracy: 0.4854\n",
      "Epoch 181/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5684 - accuracy: 0.6753 - val_loss: 1.1556 - val_accuracy: 0.5168\n",
      "Epoch 182/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.6776 - val_loss: 1.1499 - val_accuracy: 0.4945\n",
      "Epoch 183/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5687 - accuracy: 0.6766 - val_loss: 1.1739 - val_accuracy: 0.5000\n",
      "Epoch 184/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.6800 - val_loss: 1.2039 - val_accuracy: 0.5292\n",
      "Epoch 185/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5683 - accuracy: 0.6734 - val_loss: 1.1976 - val_accuracy: 0.4928\n",
      "Epoch 186/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.6776 - val_loss: 1.1610 - val_accuracy: 0.5174\n",
      "Epoch 187/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5663 - accuracy: 0.6777 - val_loss: 1.1766 - val_accuracy: 0.4993\n",
      "Epoch 188/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5649 - accuracy: 0.6782 - val_loss: 1.1331 - val_accuracy: 0.5625\n",
      "Epoch 189/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5665 - accuracy: 0.6780 - val_loss: 1.1945 - val_accuracy: 0.5288\n",
      "Epoch 190/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.6770 - val_loss: 1.1836 - val_accuracy: 0.4891\n",
      "Epoch 191/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5657 - accuracy: 0.6785 - val_loss: 1.2094 - val_accuracy: 0.4959\n",
      "Epoch 192/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5638 - accuracy: 0.6794 - val_loss: 1.2403 - val_accuracy: 0.4645\n",
      "Epoch 193/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5658 - accuracy: 0.6770 - val_loss: 1.1933 - val_accuracy: 0.4985\n",
      "Epoch 194/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5644 - accuracy: 0.6792 - val_loss: 1.2419 - val_accuracy: 0.5590\n",
      "Epoch 195/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.6763 - val_loss: 1.2391 - val_accuracy: 0.5523\n",
      "Epoch 196/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5641 - accuracy: 0.6797 - val_loss: 1.2072 - val_accuracy: 0.5361\n",
      "Epoch 197/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5636 - accuracy: 0.6791 - val_loss: 1.1766 - val_accuracy: 0.5227\n",
      "Epoch 198/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5628 - accuracy: 0.6795 - val_loss: 1.2198 - val_accuracy: 0.5181\n",
      "Epoch 199/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5624 - accuracy: 0.6786 - val_loss: 1.1297 - val_accuracy: 0.5246\n",
      "Epoch 200/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5613 - accuracy: 0.6808 - val_loss: 1.2007 - val_accuracy: 0.5226\n",
      "Epoch 201/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5640 - accuracy: 0.6800 - val_loss: 1.2120 - val_accuracy: 0.5272\n",
      "Epoch 202/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5608 - accuracy: 0.6810 - val_loss: 1.1708 - val_accuracy: 0.5335\n",
      "Epoch 203/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5627 - accuracy: 0.6796 - val_loss: 1.3074 - val_accuracy: 0.5494\n",
      "Epoch 204/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5621 - accuracy: 0.6790 - val_loss: 1.2368 - val_accuracy: 0.5279\n",
      "Epoch 205/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5614 - accuracy: 0.6810 - val_loss: 1.2033 - val_accuracy: 0.5205\n",
      "Epoch 206/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5594 - accuracy: 0.6825 - val_loss: 1.2453 - val_accuracy: 0.4963\n",
      "Epoch 207/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5613 - accuracy: 0.6787 - val_loss: 1.2266 - val_accuracy: 0.5166\n",
      "Epoch 208/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5612 - accuracy: 0.6808 - val_loss: 1.2474 - val_accuracy: 0.5536\n",
      "Epoch 209/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5619 - accuracy: 0.6808 - val_loss: 1.1987 - val_accuracy: 0.5407\n",
      "Epoch 210/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5592 - accuracy: 0.6806 - val_loss: 1.2447 - val_accuracy: 0.4909\n",
      "Epoch 211/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5599 - accuracy: 0.6827 - val_loss: 1.2150 - val_accuracy: 0.5129\n",
      "Epoch 212/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.6825 - val_loss: 1.2640 - val_accuracy: 0.5394\n",
      "Epoch 213/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5588 - accuracy: 0.6829 - val_loss: 1.2932 - val_accuracy: 0.5418\n",
      "Epoch 214/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5592 - accuracy: 0.6800 - val_loss: 1.2433 - val_accuracy: 0.4965\n",
      "Epoch 215/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5602 - accuracy: 0.6818 - val_loss: 1.3059 - val_accuracy: 0.5216\n",
      "Epoch 216/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5582 - accuracy: 0.6819 - val_loss: 1.2193 - val_accuracy: 0.5333\n",
      "Epoch 217/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5597 - accuracy: 0.6808 - val_loss: 1.2556 - val_accuracy: 0.4898\n",
      "Epoch 218/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5577 - accuracy: 0.6825 - val_loss: 1.2750 - val_accuracy: 0.5253\n",
      "Epoch 219/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5573 - accuracy: 0.6851 - val_loss: 1.2118 - val_accuracy: 0.5224\n",
      "Epoch 220/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5570 - accuracy: 0.6867 - val_loss: 1.3418 - val_accuracy: 0.4865\n",
      "Epoch 221/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.6845 - val_loss: 1.2983 - val_accuracy: 0.5560\n",
      "Epoch 222/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5570 - accuracy: 0.6845 - val_loss: 1.3114 - val_accuracy: 0.5157\n",
      "Epoch 223/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5561 - accuracy: 0.6842 - val_loss: 1.3062 - val_accuracy: 0.5281\n",
      "Epoch 224/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5574 - accuracy: 0.6838 - val_loss: 1.2866 - val_accuracy: 0.4983\n",
      "Epoch 225/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5561 - accuracy: 0.6839 - val_loss: 1.3034 - val_accuracy: 0.5015\n",
      "Epoch 226/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5566 - accuracy: 0.6827 - val_loss: 1.3615 - val_accuracy: 0.5281\n",
      "Epoch 227/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5586 - accuracy: 0.6810 - val_loss: 1.2777 - val_accuracy: 0.4885\n",
      "Epoch 228/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5548 - accuracy: 0.6842 - val_loss: 1.2621 - val_accuracy: 0.5094\n",
      "Epoch 229/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5556 - accuracy: 0.6818 - val_loss: 1.3179 - val_accuracy: 0.4920\n",
      "Epoch 230/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5539 - accuracy: 0.6844 - val_loss: 1.2923 - val_accuracy: 0.5398\n",
      "Epoch 231/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5544 - accuracy: 0.6863 - val_loss: 1.3540 - val_accuracy: 0.5109\n",
      "Epoch 232/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5564 - accuracy: 0.6843 - val_loss: 1.2845 - val_accuracy: 0.5057\n",
      "Epoch 233/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.6855 - val_loss: 1.2967 - val_accuracy: 0.5192\n",
      "Epoch 234/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5546 - accuracy: 0.6851 - val_loss: 1.3593 - val_accuracy: 0.5270\n",
      "Epoch 235/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5559 - accuracy: 0.6838 - val_loss: 1.3436 - val_accuracy: 0.5194\n",
      "Epoch 236/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5540 - accuracy: 0.6862 - val_loss: 1.3475 - val_accuracy: 0.5385\n",
      "Epoch 237/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.6860 - val_loss: 1.4028 - val_accuracy: 0.4865\n",
      "Epoch 238/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5545 - accuracy: 0.6837 - val_loss: 1.3303 - val_accuracy: 0.4817\n",
      "Epoch 239/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5535 - accuracy: 0.6832 - val_loss: 1.2876 - val_accuracy: 0.5329\n",
      "Epoch 240/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5525 - accuracy: 0.6871 - val_loss: 1.2898 - val_accuracy: 0.5242\n",
      "Epoch 241/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5540 - accuracy: 0.6841 - val_loss: 1.2698 - val_accuracy: 0.4819\n",
      "Epoch 242/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5532 - accuracy: 0.6868 - val_loss: 1.2877 - val_accuracy: 0.4915\n",
      "Epoch 243/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5525 - accuracy: 0.6865 - val_loss: 1.3346 - val_accuracy: 0.5440\n",
      "Epoch 244/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5526 - accuracy: 0.6868 - val_loss: 1.3926 - val_accuracy: 0.5309\n",
      "Epoch 245/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.6836 - val_loss: 1.3931 - val_accuracy: 0.5059\n",
      "Epoch 246/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5513 - accuracy: 0.6862 - val_loss: 1.3566 - val_accuracy: 0.4987\n",
      "Epoch 247/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5516 - accuracy: 0.6879 - val_loss: 1.3950 - val_accuracy: 0.4926\n",
      "Epoch 248/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.6864 - val_loss: 1.2694 - val_accuracy: 0.5375\n",
      "Epoch 249/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.6863 - val_loss: 1.3891 - val_accuracy: 0.5307\n",
      "Epoch 250/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5523 - accuracy: 0.6870 - val_loss: 1.3396 - val_accuracy: 0.5377\n",
      "Epoch 251/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5502 - accuracy: 0.6908 - val_loss: 1.3668 - val_accuracy: 0.5261\n",
      "Epoch 252/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.6881 - val_loss: 1.4253 - val_accuracy: 0.5325\n",
      "Epoch 253/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5506 - accuracy: 0.6869 - val_loss: 1.3843 - val_accuracy: 0.5074\n",
      "Epoch 254/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5530 - accuracy: 0.6846 - val_loss: 1.3805 - val_accuracy: 0.4928\n",
      "Epoch 255/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.6893 - val_loss: 1.3593 - val_accuracy: 0.5022\n",
      "Epoch 256/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5503 - accuracy: 0.6889 - val_loss: 1.4160 - val_accuracy: 0.5494\n",
      "Epoch 257/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5500 - accuracy: 0.6873 - val_loss: 1.4125 - val_accuracy: 0.5170\n",
      "Epoch 258/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.6909 - val_loss: 1.4143 - val_accuracy: 0.5054\n",
      "Epoch 259/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.6892 - val_loss: 1.4706 - val_accuracy: 0.5440\n",
      "Epoch 260/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5494 - accuracy: 0.6864 - val_loss: 1.3947 - val_accuracy: 0.5266\n",
      "Epoch 261/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.6888 - val_loss: 1.3727 - val_accuracy: 0.4839\n",
      "Epoch 262/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5491 - accuracy: 0.6893 - val_loss: 1.3866 - val_accuracy: 0.4926\n",
      "Epoch 263/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5494 - accuracy: 0.6883 - val_loss: 1.3951 - val_accuracy: 0.5442\n",
      "Epoch 264/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5507 - accuracy: 0.6879 - val_loss: 1.4933 - val_accuracy: 0.4972\n",
      "Epoch 265/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.6904 - val_loss: 1.3798 - val_accuracy: 0.4887\n",
      "Epoch 266/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.6903 - val_loss: 1.3886 - val_accuracy: 0.5030\n",
      "Epoch 267/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.6899 - val_loss: 1.5015 - val_accuracy: 0.5166\n",
      "Epoch 268/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.6889 - val_loss: 1.3879 - val_accuracy: 0.4669\n",
      "Epoch 269/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5498 - accuracy: 0.6880 - val_loss: 1.3676 - val_accuracy: 0.5257\n",
      "Epoch 270/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.6910 - val_loss: 1.4395 - val_accuracy: 0.4982\n",
      "Epoch 271/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.6896 - val_loss: 1.4081 - val_accuracy: 0.4978\n",
      "Epoch 272/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5484 - accuracy: 0.6920 - val_loss: 1.4782 - val_accuracy: 0.4970\n",
      "Epoch 273/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.6928 - val_loss: 1.5131 - val_accuracy: 0.5377\n",
      "Epoch 274/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.6886 - val_loss: 1.4805 - val_accuracy: 0.5372\n",
      "Epoch 275/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.6914 - val_loss: 1.5125 - val_accuracy: 0.5429\n",
      "Epoch 276/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.6903 - val_loss: 1.4201 - val_accuracy: 0.5115\n",
      "Epoch 277/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.6886 - val_loss: 1.4770 - val_accuracy: 0.5954\n",
      "Epoch 278/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.6899 - val_loss: 1.4389 - val_accuracy: 0.4957\n",
      "Epoch 279/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.6904 - val_loss: 1.4525 - val_accuracy: 0.5155\n",
      "Epoch 280/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5462 - accuracy: 0.6916 - val_loss: 1.5045 - val_accuracy: 0.5015\n",
      "Epoch 281/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.6923 - val_loss: 1.5339 - val_accuracy: 0.5020\n",
      "Epoch 282/5000\n",
      "1028/1028 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.6909 - val_loss: 1.5714 - val_accuracy: 0.4821\n",
      "Epoch 283/5000\n",
      "1028/1028 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.6894 - val_loss: 1.5249 - val_accuracy: 0.4667\n",
      "Epoch 284/5000\n",
      "1028/1028 [==============================] - 2s 1ms/step - loss: 0.5481 - accuracy: 0.6886 - val_loss: 1.4481 - val_accuracy: 0.5105\n",
      "Epoch 285/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.6921 - val_loss: 1.4531 - val_accuracy: 0.5074\n",
      "Epoch 286/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.6923 - val_loss: 1.5422 - val_accuracy: 0.5017\n",
      "Epoch 287/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5452 - accuracy: 0.6923 - val_loss: 1.4728 - val_accuracy: 0.5264\n",
      "Epoch 288/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.6875 - val_loss: 1.4987 - val_accuracy: 0.5324\n",
      "Epoch 289/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.6899 - val_loss: 1.5141 - val_accuracy: 0.5422\n",
      "Epoch 290/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.6914 - val_loss: 1.4640 - val_accuracy: 0.5560\n",
      "Epoch 291/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.6915 - val_loss: 1.5347 - val_accuracy: 0.4893\n",
      "Epoch 292/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.6909 - val_loss: 1.4550 - val_accuracy: 0.4920\n",
      "Epoch 293/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.6943 - val_loss: 1.5034 - val_accuracy: 0.5174\n",
      "Epoch 294/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.6926 - val_loss: 1.4028 - val_accuracy: 0.5080\n",
      "Epoch 295/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.6934 - val_loss: 1.4967 - val_accuracy: 0.5396\n",
      "Epoch 296/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.6918 - val_loss: 1.4574 - val_accuracy: 0.5237\n",
      "Epoch 297/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.6935 - val_loss: 1.5154 - val_accuracy: 0.5379\n",
      "Epoch 298/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.6937 - val_loss: 1.5047 - val_accuracy: 0.4750\n",
      "Epoch 299/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.6931 - val_loss: 1.4451 - val_accuracy: 0.4978\n",
      "Epoch 300/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.6953 - val_loss: 1.5883 - val_accuracy: 0.5664\n",
      "Epoch 301/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.6947 - val_loss: 1.4555 - val_accuracy: 0.5035\n",
      "Epoch 302/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.6924 - val_loss: 1.5518 - val_accuracy: 0.5192\n",
      "Epoch 303/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.6934 - val_loss: 1.5229 - val_accuracy: 0.5039\n",
      "Epoch 304/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.6947 - val_loss: 1.5405 - val_accuracy: 0.4930\n",
      "Epoch 305/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.6936 - val_loss: 1.5933 - val_accuracy: 0.5250\n",
      "Epoch 306/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.6927 - val_loss: 1.5701 - val_accuracy: 0.5287\n",
      "Epoch 307/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.6928 - val_loss: 1.5366 - val_accuracy: 0.5152\n",
      "Epoch 308/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.6933 - val_loss: 1.5131 - val_accuracy: 0.5015\n",
      "Epoch 309/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.6937 - val_loss: 1.5668 - val_accuracy: 0.5218\n",
      "Epoch 310/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.6945 - val_loss: 1.5574 - val_accuracy: 0.5383\n",
      "Epoch 311/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.6944 - val_loss: 1.5567 - val_accuracy: 0.5335\n",
      "Epoch 312/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.6954 - val_loss: 1.6040 - val_accuracy: 0.5092\n",
      "Epoch 313/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.6956 - val_loss: 1.6161 - val_accuracy: 0.5022\n",
      "Epoch 314/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.6936 - val_loss: 1.6353 - val_accuracy: 0.4828\n",
      "Epoch 315/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.6927 - val_loss: 1.5687 - val_accuracy: 0.4780\n",
      "Epoch 316/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.6929 - val_loss: 1.5582 - val_accuracy: 0.5113\n",
      "Epoch 317/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.6952 - val_loss: 1.6148 - val_accuracy: 0.5335\n",
      "Epoch 318/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.6943 - val_loss: 1.5213 - val_accuracy: 0.5052\n",
      "Epoch 319/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.6948 - val_loss: 1.6279 - val_accuracy: 0.5178\n",
      "Epoch 320/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.6973 - val_loss: 1.6600 - val_accuracy: 0.5189\n",
      "Epoch 321/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.6940 - val_loss: 1.5451 - val_accuracy: 0.4920\n",
      "Epoch 322/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.6948 - val_loss: 1.6005 - val_accuracy: 0.5072\n",
      "Epoch 323/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.6946 - val_loss: 1.4780 - val_accuracy: 0.5192\n",
      "Epoch 324/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.6949 - val_loss: 1.6475 - val_accuracy: 0.5172\n",
      "Epoch 325/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.6941 - val_loss: 1.5871 - val_accuracy: 0.5120\n",
      "Epoch 326/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.6942 - val_loss: 1.5857 - val_accuracy: 0.5172\n",
      "Epoch 327/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.6968 - val_loss: 1.6047 - val_accuracy: 0.5224\n",
      "Epoch 328/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.6948 - val_loss: 1.6172 - val_accuracy: 0.5214\n",
      "Epoch 329/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.6987 - val_loss: 1.5958 - val_accuracy: 0.5159\n",
      "Epoch 330/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.6934 - val_loss: 1.5959 - val_accuracy: 0.5031\n",
      "Epoch 331/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.6976 - val_loss: 1.5833 - val_accuracy: 0.5185\n",
      "Epoch 332/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.6972 - val_loss: 1.5243 - val_accuracy: 0.5227\n",
      "Epoch 333/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.6960 - val_loss: 1.6453 - val_accuracy: 0.5142\n",
      "Epoch 334/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.6955 - val_loss: 1.6477 - val_accuracy: 0.5357\n",
      "Epoch 335/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.6964 - val_loss: 1.7012 - val_accuracy: 0.5000\n",
      "Epoch 336/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.6937 - val_loss: 1.6079 - val_accuracy: 0.5081\n",
      "Epoch 337/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.6953 - val_loss: 1.5673 - val_accuracy: 0.4939\n",
      "Epoch 338/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.6947 - val_loss: 1.6613 - val_accuracy: 0.5374\n",
      "Epoch 339/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.6978 - val_loss: 1.6191 - val_accuracy: 0.5438\n",
      "Epoch 340/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.6954 - val_loss: 1.6312 - val_accuracy: 0.5594\n",
      "Epoch 341/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.6969 - val_loss: 1.5635 - val_accuracy: 0.5126\n",
      "Epoch 342/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.6976 - val_loss: 1.5838 - val_accuracy: 0.5185\n",
      "Epoch 343/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.6952 - val_loss: 1.6461 - val_accuracy: 0.5198\n",
      "Epoch 344/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.6974 - val_loss: 1.6065 - val_accuracy: 0.4996\n",
      "Epoch 345/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.6988 - val_loss: 1.7355 - val_accuracy: 0.5322\n",
      "Epoch 346/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.6961 - val_loss: 1.7236 - val_accuracy: 0.4889\n",
      "Epoch 347/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.6949 - val_loss: 1.7561 - val_accuracy: 0.5242\n",
      "Epoch 348/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.6932 - val_loss: 1.6411 - val_accuracy: 0.5362\n",
      "Epoch 349/5000\n",
      "1028/1028 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.6951 - val_loss: 1.7266 - val_accuracy: 0.5218\n",
      "Epoch 350/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.6983 - val_loss: 1.6776 - val_accuracy: 0.4974\n",
      "Epoch 351/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.6989 - val_loss: 1.6366 - val_accuracy: 0.4989\n",
      "Epoch 352/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.6995 - val_loss: 1.6617 - val_accuracy: 0.4795\n",
      "Epoch 353/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.6981 - val_loss: 1.6624 - val_accuracy: 0.5165\n",
      "Epoch 354/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.6978 - val_loss: 1.6746 - val_accuracy: 0.5017\n",
      "Epoch 355/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.6959 - val_loss: 1.6134 - val_accuracy: 0.4898\n",
      "Epoch 356/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.6977 - val_loss: 1.6611 - val_accuracy: 0.4919\n",
      "Epoch 357/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.6969 - val_loss: 1.6499 - val_accuracy: 0.5096\n",
      "Epoch 358/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.6960 - val_loss: 1.7366 - val_accuracy: 0.5148\n",
      "Epoch 359/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.6980 - val_loss: 1.6974 - val_accuracy: 0.5153\n",
      "Epoch 360/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.6982 - val_loss: 1.7607 - val_accuracy: 0.5190\n",
      "Epoch 361/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.6962 - val_loss: 1.6285 - val_accuracy: 0.5007\n",
      "Epoch 362/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.6979 - val_loss: 1.6756 - val_accuracy: 0.4993\n",
      "Epoch 363/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.6977 - val_loss: 1.5659 - val_accuracy: 0.5072\n",
      "Epoch 364/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.6975 - val_loss: 1.7069 - val_accuracy: 0.5076\n",
      "Epoch 365/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.6979 - val_loss: 1.5699 - val_accuracy: 0.4884\n",
      "Epoch 366/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.6997 - val_loss: 1.6766 - val_accuracy: 0.5018\n",
      "Epoch 367/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.6984 - val_loss: 1.5906 - val_accuracy: 0.5250\n",
      "Epoch 368/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.6990 - val_loss: 1.7840 - val_accuracy: 0.5226\n",
      "Epoch 369/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.6982 - val_loss: 1.7109 - val_accuracy: 0.5202\n",
      "Epoch 370/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.6968 - val_loss: 1.7429 - val_accuracy: 0.5122\n",
      "Epoch 371/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7001 - val_loss: 1.6772 - val_accuracy: 0.5111\n",
      "Epoch 372/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.6992 - val_loss: 1.8060 - val_accuracy: 0.5405\n",
      "Epoch 373/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7000 - val_loss: 1.7867 - val_accuracy: 0.5374\n",
      "Epoch 374/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.6993 - val_loss: 1.7579 - val_accuracy: 0.4972\n",
      "Epoch 375/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.6969 - val_loss: 1.7964 - val_accuracy: 0.5018\n",
      "Epoch 376/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7003 - val_loss: 1.7665 - val_accuracy: 0.5057\n",
      "Epoch 377/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.6995 - val_loss: 1.8375 - val_accuracy: 0.5174\n",
      "Epoch 378/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5325 - accuracy: 0.6992 - val_loss: 1.8191 - val_accuracy: 0.4859\n",
      "Epoch 379/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5327 - accuracy: 0.7004 - val_loss: 1.7382 - val_accuracy: 0.5070\n",
      "Epoch 380/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.6998 - val_loss: 1.8101 - val_accuracy: 0.5007\n",
      "Epoch 381/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7001 - val_loss: 1.7465 - val_accuracy: 0.5301\n",
      "Epoch 382/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.6990 - val_loss: 1.7293 - val_accuracy: 0.4933\n",
      "Epoch 383/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.6984 - val_loss: 1.8308 - val_accuracy: 0.5701\n",
      "Epoch 384/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.6999 - val_loss: 1.7084 - val_accuracy: 0.4867\n",
      "Epoch 385/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5315 - accuracy: 0.6989 - val_loss: 1.7724 - val_accuracy: 0.5070\n",
      "Epoch 386/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.6990 - val_loss: 1.7661 - val_accuracy: 0.4935\n",
      "Epoch 387/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.6999 - val_loss: 1.7980 - val_accuracy: 0.5002\n",
      "Epoch 388/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.6974 - val_loss: 1.6446 - val_accuracy: 0.5189\n",
      "Epoch 389/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.6982 - val_loss: 1.8904 - val_accuracy: 0.4869\n",
      "Epoch 390/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.6977 - val_loss: 1.7364 - val_accuracy: 0.5229\n",
      "Epoch 391/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.6995 - val_loss: 1.8088 - val_accuracy: 0.4941\n",
      "Epoch 392/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.6984 - val_loss: 1.6697 - val_accuracy: 0.5092\n",
      "Epoch 393/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5325 - accuracy: 0.7005 - val_loss: 1.8290 - val_accuracy: 0.5078\n",
      "Epoch 394/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.6985 - val_loss: 1.9071 - val_accuracy: 0.4957\n",
      "Epoch 395/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5318 - accuracy: 0.7005 - val_loss: 1.7628 - val_accuracy: 0.4932\n",
      "Epoch 396/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5319 - accuracy: 0.6995 - val_loss: 1.7819 - val_accuracy: 0.5290\n",
      "Epoch 397/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5302 - accuracy: 0.7024 - val_loss: 1.8564 - val_accuracy: 0.5187\n",
      "Epoch 398/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.6985 - val_loss: 1.7617 - val_accuracy: 0.4965\n",
      "Epoch 399/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5325 - accuracy: 0.6983 - val_loss: 1.7893 - val_accuracy: 0.5113\n",
      "Epoch 400/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5298 - accuracy: 0.7023 - val_loss: 1.7576 - val_accuracy: 0.5044\n",
      "Epoch 401/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7013 - val_loss: 1.7888 - val_accuracy: 0.5205\n",
      "Epoch 402/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5309 - accuracy: 0.7021 - val_loss: 1.8244 - val_accuracy: 0.5361\n",
      "Epoch 403/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5315 - accuracy: 0.7018 - val_loss: 1.7784 - val_accuracy: 0.5433\n",
      "Epoch 404/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7012 - val_loss: 1.8342 - val_accuracy: 0.5327\n",
      "Epoch 405/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.6995 - val_loss: 1.8681 - val_accuracy: 0.5207\n",
      "Epoch 406/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5302 - accuracy: 0.7026 - val_loss: 1.8091 - val_accuracy: 0.5046\n",
      "Epoch 407/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5321 - accuracy: 0.7006 - val_loss: 1.7675 - val_accuracy: 0.5266\n",
      "Epoch 408/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5313 - accuracy: 0.7000 - val_loss: 1.8569 - val_accuracy: 0.5046\n",
      "Epoch 409/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7003 - val_loss: 1.8442 - val_accuracy: 0.4843\n",
      "Epoch 410/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7033 - val_loss: 1.8237 - val_accuracy: 0.5268\n",
      "Epoch 411/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5284 - accuracy: 0.7017 - val_loss: 1.7682 - val_accuracy: 0.5043\n",
      "Epoch 412/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.6996 - val_loss: 1.7953 - val_accuracy: 0.5246\n",
      "Epoch 413/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5294 - accuracy: 0.7014 - val_loss: 1.8168 - val_accuracy: 0.5198\n",
      "Epoch 414/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7026 - val_loss: 1.7585 - val_accuracy: 0.5239\n",
      "Epoch 415/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5306 - accuracy: 0.7024 - val_loss: 1.8228 - val_accuracy: 0.5080\n",
      "Epoch 416/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5311 - accuracy: 0.7008 - val_loss: 1.7807 - val_accuracy: 0.5030\n",
      "Epoch 417/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5304 - accuracy: 0.7026 - val_loss: 1.8730 - val_accuracy: 0.5218\n",
      "Epoch 418/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5305 - accuracy: 0.7027 - val_loss: 1.8434 - val_accuracy: 0.5170\n",
      "Epoch 419/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.6999 - val_loss: 1.8106 - val_accuracy: 0.5279\n",
      "Epoch 420/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5314 - accuracy: 0.7000 - val_loss: 1.8446 - val_accuracy: 0.5285\n",
      "Epoch 421/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5296 - accuracy: 0.7012 - val_loss: 1.8809 - val_accuracy: 0.5409\n",
      "Epoch 422/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5283 - accuracy: 0.7043 - val_loss: 1.8024 - val_accuracy: 0.4928\n",
      "Epoch 423/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5313 - accuracy: 0.7003 - val_loss: 1.8016 - val_accuracy: 0.4797\n",
      "Epoch 424/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5297 - accuracy: 0.7014 - val_loss: 1.8225 - val_accuracy: 0.5200\n",
      "Epoch 425/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5293 - accuracy: 0.7012 - val_loss: 1.8927 - val_accuracy: 0.5316\n",
      "Epoch 426/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7008 - val_loss: 1.8716 - val_accuracy: 0.5116\n",
      "Epoch 427/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7040 - val_loss: 1.9057 - val_accuracy: 0.5368\n",
      "Epoch 428/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5294 - accuracy: 0.7032 - val_loss: 1.9519 - val_accuracy: 0.5335\n",
      "Epoch 429/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5311 - accuracy: 0.7011 - val_loss: 1.8129 - val_accuracy: 0.5189\n",
      "Epoch 430/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7003 - val_loss: 1.8360 - val_accuracy: 0.5163\n",
      "Epoch 431/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5306 - accuracy: 0.7031 - val_loss: 1.7956 - val_accuracy: 0.5085\n",
      "Epoch 432/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5267 - accuracy: 0.7040 - val_loss: 1.8029 - val_accuracy: 0.4989\n",
      "Epoch 433/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7045 - val_loss: 1.7967 - val_accuracy: 0.5399\n",
      "Epoch 434/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5286 - accuracy: 0.7018 - val_loss: 1.8668 - val_accuracy: 0.5183\n",
      "Epoch 435/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5280 - accuracy: 0.7030 - val_loss: 1.8265 - val_accuracy: 0.4961\n",
      "Epoch 436/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7013 - val_loss: 1.9666 - val_accuracy: 0.5244\n",
      "Epoch 437/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.6997 - val_loss: 1.7922 - val_accuracy: 0.5076\n",
      "Epoch 438/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7024 - val_loss: 1.7757 - val_accuracy: 0.5216\n",
      "Epoch 439/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7012 - val_loss: 1.9115 - val_accuracy: 0.5037\n",
      "Epoch 440/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5282 - accuracy: 0.7031 - val_loss: 1.9107 - val_accuracy: 0.5002\n",
      "Epoch 441/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5291 - accuracy: 0.7013 - val_loss: 1.8747 - val_accuracy: 0.5089\n",
      "Epoch 442/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5300 - accuracy: 0.7002 - val_loss: 1.8962 - val_accuracy: 0.5242\n",
      "Epoch 443/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5272 - accuracy: 0.7031 - val_loss: 1.8791 - val_accuracy: 0.5312\n",
      "Epoch 444/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5295 - accuracy: 0.7004 - val_loss: 1.9618 - val_accuracy: 0.5277\n",
      "Epoch 445/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5298 - accuracy: 0.7029 - val_loss: 1.9563 - val_accuracy: 0.5004\n",
      "Epoch 446/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5276 - accuracy: 0.7028 - val_loss: 1.9609 - val_accuracy: 0.5072\n",
      "Epoch 447/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5280 - accuracy: 0.7017 - val_loss: 1.8575 - val_accuracy: 0.4961\n",
      "Epoch 448/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5269 - accuracy: 0.7016 - val_loss: 1.9339 - val_accuracy: 0.5357\n",
      "Epoch 449/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5277 - accuracy: 0.7048 - val_loss: 2.0220 - val_accuracy: 0.5240\n",
      "Epoch 450/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5258 - accuracy: 0.7031 - val_loss: 1.9803 - val_accuracy: 0.5092\n",
      "Epoch 451/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7025 - val_loss: 1.8995 - val_accuracy: 0.5068\n",
      "Epoch 452/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5283 - accuracy: 0.7026 - val_loss: 1.8875 - val_accuracy: 0.4996\n",
      "Epoch 453/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7015 - val_loss: 1.8735 - val_accuracy: 0.5366\n",
      "Epoch 454/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5282 - accuracy: 0.7038 - val_loss: 1.9454 - val_accuracy: 0.5263\n",
      "Epoch 455/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5298 - accuracy: 0.7010 - val_loss: 2.0022 - val_accuracy: 0.5338\n",
      "Epoch 456/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5263 - accuracy: 0.7054 - val_loss: 1.8711 - val_accuracy: 0.4980\n",
      "Epoch 457/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5273 - accuracy: 0.7050 - val_loss: 2.0184 - val_accuracy: 0.5115\n",
      "Epoch 458/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5278 - accuracy: 0.7033 - val_loss: 1.8786 - val_accuracy: 0.5268\n",
      "Epoch 459/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5289 - accuracy: 0.7026 - val_loss: 1.9351 - val_accuracy: 0.5115\n",
      "Epoch 460/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5257 - accuracy: 0.7058 - val_loss: 2.0932 - val_accuracy: 0.5041\n",
      "Epoch 461/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5271 - accuracy: 0.7042 - val_loss: 1.9846 - val_accuracy: 0.4926\n",
      "Epoch 462/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5281 - accuracy: 0.7009 - val_loss: 2.0022 - val_accuracy: 0.5298\n",
      "Epoch 463/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5298 - accuracy: 0.7013 - val_loss: 1.9811 - val_accuracy: 0.5202\n",
      "Epoch 464/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5284 - accuracy: 0.7041 - val_loss: 1.9931 - val_accuracy: 0.4847\n",
      "Epoch 465/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5274 - accuracy: 0.7028 - val_loss: 1.9039 - val_accuracy: 0.5172\n",
      "Epoch 466/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5287 - accuracy: 0.7024 - val_loss: 1.9666 - val_accuracy: 0.5080\n",
      "Epoch 467/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.7039 - val_loss: 2.0112 - val_accuracy: 0.5159\n",
      "Epoch 468/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5289 - accuracy: 0.7025 - val_loss: 2.0373 - val_accuracy: 0.5222\n",
      "Epoch 469/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5270 - accuracy: 0.7046 - val_loss: 1.9738 - val_accuracy: 0.5111\n",
      "Epoch 470/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7040 - val_loss: 2.0188 - val_accuracy: 0.5416\n",
      "Epoch 471/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5249 - accuracy: 0.7047 - val_loss: 2.1032 - val_accuracy: 0.5510\n",
      "Epoch 472/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5278 - accuracy: 0.7036 - val_loss: 1.9949 - val_accuracy: 0.5187\n",
      "Epoch 473/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5262 - accuracy: 0.7026 - val_loss: 2.0726 - val_accuracy: 0.5259\n",
      "Epoch 474/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5261 - accuracy: 0.7052 - val_loss: 2.0319 - val_accuracy: 0.5244\n",
      "Epoch 475/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7043 - val_loss: 1.8855 - val_accuracy: 0.5150\n",
      "Epoch 476/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5274 - accuracy: 0.7037 - val_loss: 1.9673 - val_accuracy: 0.5274\n",
      "Epoch 477/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5276 - accuracy: 0.7021 - val_loss: 1.9919 - val_accuracy: 0.5165\n",
      "Epoch 478/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5249 - accuracy: 0.7068 - val_loss: 2.0512 - val_accuracy: 0.5135\n",
      "Epoch 479/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7027 - val_loss: 1.9410 - val_accuracy: 0.4919\n",
      "Epoch 480/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5281 - accuracy: 0.7041 - val_loss: 2.0256 - val_accuracy: 0.5242\n",
      "Epoch 481/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5246 - accuracy: 0.7027 - val_loss: 2.0909 - val_accuracy: 0.5022\n",
      "Epoch 482/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5253 - accuracy: 0.7042 - val_loss: 2.0602 - val_accuracy: 0.5296\n",
      "Epoch 483/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5268 - accuracy: 0.7042 - val_loss: 1.9551 - val_accuracy: 0.5178\n",
      "Epoch 484/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5262 - accuracy: 0.7055 - val_loss: 2.0286 - val_accuracy: 0.4839\n",
      "Epoch 485/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5253 - accuracy: 0.7052 - val_loss: 1.9457 - val_accuracy: 0.4937\n",
      "Epoch 486/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5272 - accuracy: 0.7037 - val_loss: 2.0313 - val_accuracy: 0.5094\n",
      "Epoch 487/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5262 - accuracy: 0.7036 - val_loss: 2.0690 - val_accuracy: 0.5340\n",
      "Epoch 488/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5269 - accuracy: 0.7018 - val_loss: 2.0721 - val_accuracy: 0.5351\n",
      "Epoch 489/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5258 - accuracy: 0.7040 - val_loss: 2.1422 - val_accuracy: 0.5386\n",
      "Epoch 490/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5244 - accuracy: 0.7053 - val_loss: 1.9335 - val_accuracy: 0.4795\n",
      "Epoch 491/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5301 - accuracy: 0.7034 - val_loss: 2.0368 - val_accuracy: 0.5429\n",
      "Epoch 492/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5231 - accuracy: 0.7059 - val_loss: 2.0605 - val_accuracy: 0.5002\n",
      "Epoch 493/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5283 - accuracy: 0.7016 - val_loss: 2.1809 - val_accuracy: 0.5174\n",
      "Epoch 494/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5285 - accuracy: 0.7045 - val_loss: 1.9808 - val_accuracy: 0.5115\n",
      "Epoch 495/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5230 - accuracy: 0.7048 - val_loss: 2.0116 - val_accuracy: 0.5072\n",
      "Epoch 496/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5241 - accuracy: 0.7069 - val_loss: 2.1240 - val_accuracy: 0.5298\n",
      "Epoch 497/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7044 - val_loss: 1.9972 - val_accuracy: 0.5237\n",
      "Epoch 498/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5250 - accuracy: 0.7045 - val_loss: 2.0050 - val_accuracy: 0.5078\n",
      "Epoch 499/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5239 - accuracy: 0.7059 - val_loss: 1.9824 - val_accuracy: 0.4978\n",
      "Epoch 500/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5260 - accuracy: 0.7045 - val_loss: 2.0602 - val_accuracy: 0.5325\n",
      "Epoch 501/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5261 - accuracy: 0.7053 - val_loss: 2.0492 - val_accuracy: 0.4874\n",
      "Epoch 502/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5223 - accuracy: 0.7062 - val_loss: 2.0589 - val_accuracy: 0.5083\n",
      "Epoch 503/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5226 - accuracy: 0.7070 - val_loss: 2.0889 - val_accuracy: 0.5124\n",
      "Epoch 504/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5266 - accuracy: 0.7036 - val_loss: 2.0724 - val_accuracy: 0.5057\n",
      "Epoch 505/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5246 - accuracy: 0.7060 - val_loss: 2.0766 - val_accuracy: 0.5237\n",
      "Epoch 506/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5260 - accuracy: 0.7059 - val_loss: 2.1552 - val_accuracy: 0.4959\n",
      "Epoch 507/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5253 - accuracy: 0.7055 - val_loss: 2.1018 - val_accuracy: 0.4743\n",
      "Epoch 508/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5252 - accuracy: 0.7055 - val_loss: 2.0537 - val_accuracy: 0.5009\n",
      "Epoch 509/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5219 - accuracy: 0.7066 - val_loss: 2.0867 - val_accuracy: 0.5087\n",
      "Epoch 510/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5240 - accuracy: 0.7070 - val_loss: 1.9908 - val_accuracy: 0.4956\n",
      "Epoch 511/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5277 - accuracy: 0.7030 - val_loss: 2.0996 - val_accuracy: 0.5057\n",
      "Epoch 512/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5230 - accuracy: 0.7068 - val_loss: 2.0346 - val_accuracy: 0.5035\n",
      "Epoch 513/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5240 - accuracy: 0.7057 - val_loss: 2.0765 - val_accuracy: 0.5100\n",
      "Epoch 514/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5263 - accuracy: 0.7046 - val_loss: 1.9174 - val_accuracy: 0.4863\n",
      "Epoch 515/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5225 - accuracy: 0.7068 - val_loss: 2.1271 - val_accuracy: 0.5253\n",
      "Epoch 516/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5231 - accuracy: 0.7042 - val_loss: 2.2168 - val_accuracy: 0.5342\n",
      "Epoch 517/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5217 - accuracy: 0.7066 - val_loss: 2.1506 - val_accuracy: 0.5231\n",
      "Epoch 518/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5253 - accuracy: 0.7054 - val_loss: 2.0909 - val_accuracy: 0.5128\n",
      "Epoch 519/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5256 - accuracy: 0.7035 - val_loss: 1.9852 - val_accuracy: 0.4972\n",
      "Epoch 520/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5220 - accuracy: 0.7057 - val_loss: 2.2056 - val_accuracy: 0.5115\n",
      "Epoch 521/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5242 - accuracy: 0.7039 - val_loss: 2.1476 - val_accuracy: 0.5451\n",
      "Epoch 522/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5241 - accuracy: 0.7040 - val_loss: 1.9857 - val_accuracy: 0.4976\n",
      "Epoch 523/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7048 - val_loss: 2.0771 - val_accuracy: 0.5183\n",
      "Epoch 524/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5248 - accuracy: 0.7062 - val_loss: 2.1075 - val_accuracy: 0.5150\n",
      "Epoch 525/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5217 - accuracy: 0.7060 - val_loss: 1.9763 - val_accuracy: 0.5514\n",
      "Epoch 526/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5211 - accuracy: 0.7067 - val_loss: 2.1076 - val_accuracy: 0.4959\n",
      "Epoch 527/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7054 - val_loss: 2.0819 - val_accuracy: 0.5246\n",
      "Epoch 528/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5228 - accuracy: 0.7061 - val_loss: 2.0583 - val_accuracy: 0.4969\n",
      "Epoch 529/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5222 - accuracy: 0.7079 - val_loss: 2.0527 - val_accuracy: 0.4880\n",
      "Epoch 530/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5229 - accuracy: 0.7076 - val_loss: 2.2056 - val_accuracy: 0.5054\n",
      "Epoch 531/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5255 - accuracy: 0.7066 - val_loss: 2.1437 - val_accuracy: 0.5181\n",
      "Epoch 532/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5245 - accuracy: 0.7060 - val_loss: 2.0758 - val_accuracy: 0.5081\n",
      "Epoch 533/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5205 - accuracy: 0.7086 - val_loss: 2.1726 - val_accuracy: 0.5381\n",
      "Epoch 534/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5229 - accuracy: 0.7049 - val_loss: 2.1679 - val_accuracy: 0.5181\n",
      "Epoch 535/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5238 - accuracy: 0.7077 - val_loss: 2.1220 - val_accuracy: 0.5063\n",
      "Epoch 536/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5214 - accuracy: 0.7083 - val_loss: 2.2637 - val_accuracy: 0.5200\n",
      "Epoch 537/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5209 - accuracy: 0.7089 - val_loss: 2.1284 - val_accuracy: 0.5263\n",
      "Epoch 538/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5220 - accuracy: 0.7092 - val_loss: 2.0251 - val_accuracy: 0.5472\n",
      "Epoch 539/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7076 - val_loss: 2.2947 - val_accuracy: 0.5211\n",
      "Epoch 540/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5209 - accuracy: 0.7057 - val_loss: 2.0914 - val_accuracy: 0.5133\n",
      "Epoch 541/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5209 - accuracy: 0.7062 - val_loss: 2.1318 - val_accuracy: 0.5146\n",
      "Epoch 542/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5233 - accuracy: 0.7048 - val_loss: 2.1188 - val_accuracy: 0.5190\n",
      "Epoch 543/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5240 - accuracy: 0.7072 - val_loss: 2.1803 - val_accuracy: 0.5229\n",
      "Epoch 544/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7068 - val_loss: 2.2482 - val_accuracy: 0.5170\n",
      "Epoch 545/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5214 - accuracy: 0.7058 - val_loss: 2.2240 - val_accuracy: 0.5335\n",
      "Epoch 546/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5232 - accuracy: 0.7060 - val_loss: 2.2041 - val_accuracy: 0.5272\n",
      "Epoch 547/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5215 - accuracy: 0.7074 - val_loss: 2.1270 - val_accuracy: 0.5159\n",
      "Epoch 548/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5224 - accuracy: 0.7069 - val_loss: 2.1824 - val_accuracy: 0.5052\n",
      "Epoch 549/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5220 - accuracy: 0.7049 - val_loss: 2.0291 - val_accuracy: 0.5163\n",
      "Epoch 550/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5210 - accuracy: 0.7051 - val_loss: 2.2050 - val_accuracy: 0.5139\n",
      "Epoch 551/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5220 - accuracy: 0.7071 - val_loss: 2.2647 - val_accuracy: 0.5340\n",
      "Epoch 552/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5200 - accuracy: 0.7067 - val_loss: 2.1061 - val_accuracy: 0.4874\n",
      "Epoch 553/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5237 - accuracy: 0.7061 - val_loss: 2.2288 - val_accuracy: 0.5157\n",
      "Epoch 554/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5216 - accuracy: 0.7052 - val_loss: 2.1787 - val_accuracy: 0.5523\n",
      "Epoch 555/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5224 - accuracy: 0.7081 - val_loss: 2.2636 - val_accuracy: 0.4884\n",
      "Epoch 556/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5197 - accuracy: 0.7089 - val_loss: 2.1586 - val_accuracy: 0.5072\n",
      "Epoch 557/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5213 - accuracy: 0.7060 - val_loss: 2.1535 - val_accuracy: 0.5059\n",
      "Epoch 558/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5199 - accuracy: 0.7090 - val_loss: 2.1958 - val_accuracy: 0.5028\n",
      "Epoch 559/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5212 - accuracy: 0.7069 - val_loss: 2.2532 - val_accuracy: 0.5146\n",
      "Epoch 560/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5211 - accuracy: 0.7069 - val_loss: 2.2927 - val_accuracy: 0.5224\n",
      "Epoch 561/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5193 - accuracy: 0.7086 - val_loss: 2.2344 - val_accuracy: 0.5181\n",
      "Epoch 562/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5246 - accuracy: 0.7056 - val_loss: 2.0988 - val_accuracy: 0.5327\n",
      "Epoch 563/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5197 - accuracy: 0.7069 - val_loss: 2.2061 - val_accuracy: 0.5174\n",
      "Epoch 564/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7084 - val_loss: 2.3195 - val_accuracy: 0.5420\n",
      "Epoch 565/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5213 - accuracy: 0.7089 - val_loss: 2.1959 - val_accuracy: 0.5329\n",
      "Epoch 566/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5248 - accuracy: 0.7051 - val_loss: 2.0074 - val_accuracy: 0.4848\n",
      "Epoch 567/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5216 - accuracy: 0.7076 - val_loss: 2.3352 - val_accuracy: 0.4913\n",
      "Epoch 568/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5195 - accuracy: 0.7081 - val_loss: 2.2810 - val_accuracy: 0.5139\n",
      "Epoch 569/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5212 - accuracy: 0.7059 - val_loss: 2.2289 - val_accuracy: 0.4874\n",
      "Epoch 570/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5222 - accuracy: 0.7083 - val_loss: 2.2149 - val_accuracy: 0.5109\n",
      "Epoch 571/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5207 - accuracy: 0.7080 - val_loss: 2.1607 - val_accuracy: 0.5179\n",
      "Epoch 572/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5215 - accuracy: 0.7060 - val_loss: 2.2949 - val_accuracy: 0.5080\n",
      "Epoch 573/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5207 - accuracy: 0.7091 - val_loss: 2.2252 - val_accuracy: 0.5059\n",
      "Epoch 574/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.7080 - val_loss: 2.1987 - val_accuracy: 0.4948\n",
      "Epoch 575/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5243 - accuracy: 0.7059 - val_loss: 2.2139 - val_accuracy: 0.5033\n",
      "Epoch 576/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5200 - accuracy: 0.7078 - val_loss: 2.1892 - val_accuracy: 0.5059\n",
      "Epoch 577/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7076 - val_loss: 2.1698 - val_accuracy: 0.5353\n",
      "Epoch 578/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5204 - accuracy: 0.7073 - val_loss: 2.1159 - val_accuracy: 0.5185\n",
      "Epoch 579/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5187 - accuracy: 0.7074 - val_loss: 2.3270 - val_accuracy: 0.5248\n",
      "Epoch 580/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5207 - accuracy: 0.7096 - val_loss: 2.3777 - val_accuracy: 0.5104\n",
      "Epoch 581/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7073 - val_loss: 2.2712 - val_accuracy: 0.5120\n",
      "Epoch 582/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5193 - accuracy: 0.7083 - val_loss: 2.1957 - val_accuracy: 0.4913\n",
      "Epoch 583/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.7085 - val_loss: 2.2557 - val_accuracy: 0.5200\n",
      "Epoch 584/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7068 - val_loss: 2.2433 - val_accuracy: 0.5320\n",
      "Epoch 585/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5201 - accuracy: 0.7076 - val_loss: 2.1779 - val_accuracy: 0.4911\n",
      "Epoch 586/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5210 - accuracy: 0.7066 - val_loss: 2.2168 - val_accuracy: 0.4859\n",
      "Epoch 587/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5190 - accuracy: 0.7094 - val_loss: 2.2630 - val_accuracy: 0.5298\n",
      "Epoch 588/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5205 - accuracy: 0.7066 - val_loss: 2.3867 - val_accuracy: 0.5009\n",
      "Epoch 589/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5224 - accuracy: 0.7062 - val_loss: 2.2941 - val_accuracy: 0.5168\n",
      "Epoch 590/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5191 - accuracy: 0.7081 - val_loss: 2.2960 - val_accuracy: 0.5007\n",
      "Epoch 591/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5240 - accuracy: 0.7060 - val_loss: 2.1785 - val_accuracy: 0.5359\n",
      "Epoch 592/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5208 - accuracy: 0.7085 - val_loss: 2.3041 - val_accuracy: 0.5372\n",
      "Epoch 593/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5210 - accuracy: 0.7062 - val_loss: 2.1329 - val_accuracy: 0.4891\n",
      "Epoch 594/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5179 - accuracy: 0.7078 - val_loss: 2.2798 - val_accuracy: 0.5020\n",
      "Epoch 595/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5192 - accuracy: 0.7093 - val_loss: 2.1839 - val_accuracy: 0.5161\n",
      "Epoch 596/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5190 - accuracy: 0.7087 - val_loss: 2.0697 - val_accuracy: 0.5290\n",
      "Epoch 597/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5187 - accuracy: 0.7095 - val_loss: 2.3287 - val_accuracy: 0.5298\n",
      "Epoch 598/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5182 - accuracy: 0.7092 - val_loss: 2.3360 - val_accuracy: 0.5250\n",
      "Epoch 599/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5235 - accuracy: 0.7076 - val_loss: 2.2714 - val_accuracy: 0.5353\n",
      "Epoch 600/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5184 - accuracy: 0.7072 - val_loss: 2.4768 - val_accuracy: 0.5087\n",
      "Epoch 601/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7072 - val_loss: 2.3452 - val_accuracy: 0.5222\n",
      "Epoch 602/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5197 - accuracy: 0.7080 - val_loss: 2.3533 - val_accuracy: 0.4891\n",
      "Epoch 603/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5191 - accuracy: 0.7068 - val_loss: 2.1796 - val_accuracy: 0.5120\n",
      "Epoch 604/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5199 - accuracy: 0.7068 - val_loss: 2.3245 - val_accuracy: 0.5102\n",
      "Epoch 605/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5183 - accuracy: 0.7079 - val_loss: 2.2943 - val_accuracy: 0.5242\n",
      "Epoch 606/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.7085 - val_loss: 2.4135 - val_accuracy: 0.5312\n",
      "Epoch 607/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5197 - accuracy: 0.7072 - val_loss: 2.3288 - val_accuracy: 0.5412\n",
      "Epoch 608/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7079 - val_loss: 2.2139 - val_accuracy: 0.5046\n",
      "Epoch 609/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5175 - accuracy: 0.7109 - val_loss: 2.4029 - val_accuracy: 0.5205\n",
      "Epoch 610/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5178 - accuracy: 0.7079 - val_loss: 2.4228 - val_accuracy: 0.5105\n",
      "Epoch 611/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7077 - val_loss: 2.3875 - val_accuracy: 0.5043\n",
      "Epoch 612/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5192 - accuracy: 0.7097 - val_loss: 2.2028 - val_accuracy: 0.5120\n",
      "Epoch 613/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7091 - val_loss: 2.3940 - val_accuracy: 0.5505\n",
      "Epoch 614/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.7085 - val_loss: 2.2906 - val_accuracy: 0.5324\n",
      "Epoch 615/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5176 - accuracy: 0.7101 - val_loss: 2.2291 - val_accuracy: 0.5011\n",
      "Epoch 616/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5218 - accuracy: 0.7071 - val_loss: 2.1860 - val_accuracy: 0.4993\n",
      "Epoch 617/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5180 - accuracy: 0.7107 - val_loss: 2.2815 - val_accuracy: 0.5244\n",
      "Epoch 618/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7080 - val_loss: 2.3981 - val_accuracy: 0.5011\n",
      "Epoch 619/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5195 - accuracy: 0.7098 - val_loss: 2.1717 - val_accuracy: 0.5092\n",
      "Epoch 620/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7082 - val_loss: 2.2951 - val_accuracy: 0.4972\n",
      "Epoch 621/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5185 - accuracy: 0.7074 - val_loss: 2.2984 - val_accuracy: 0.5006\n",
      "Epoch 622/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5216 - accuracy: 0.7074 - val_loss: 2.2267 - val_accuracy: 0.5396\n",
      "Epoch 623/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5182 - accuracy: 0.7105 - val_loss: 2.4635 - val_accuracy: 0.5202\n",
      "Epoch 624/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5190 - accuracy: 0.7085 - val_loss: 2.3951 - val_accuracy: 0.5198\n",
      "Epoch 625/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7079 - val_loss: 2.3629 - val_accuracy: 0.5316\n",
      "Epoch 626/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5187 - accuracy: 0.7078 - val_loss: 2.4222 - val_accuracy: 0.5105\n",
      "Epoch 627/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5204 - accuracy: 0.7095 - val_loss: 2.2025 - val_accuracy: 0.5209\n",
      "Epoch 628/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.7090 - val_loss: 2.5996 - val_accuracy: 0.5325\n",
      "Epoch 629/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5186 - accuracy: 0.7082 - val_loss: 2.3565 - val_accuracy: 0.5174\n",
      "Epoch 630/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5231 - accuracy: 0.7079 - val_loss: 2.4804 - val_accuracy: 0.5392\n",
      "Epoch 631/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5182 - accuracy: 0.7096 - val_loss: 2.3841 - val_accuracy: 0.5364\n",
      "Epoch 632/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5164 - accuracy: 0.7106 - val_loss: 2.3661 - val_accuracy: 0.5490\n",
      "Epoch 633/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5164 - accuracy: 0.7105 - val_loss: 2.3988 - val_accuracy: 0.5050\n",
      "Epoch 634/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5166 - accuracy: 0.7095 - val_loss: 2.3714 - val_accuracy: 0.5068\n",
      "Epoch 635/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5221 - accuracy: 0.7074 - val_loss: 2.3357 - val_accuracy: 0.5070\n",
      "Epoch 636/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5167 - accuracy: 0.7115 - val_loss: 2.3743 - val_accuracy: 0.5196\n",
      "Epoch 637/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5195 - accuracy: 0.7099 - val_loss: 2.5262 - val_accuracy: 0.5146\n",
      "Epoch 638/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5181 - accuracy: 0.7100 - val_loss: 2.3089 - val_accuracy: 0.5054\n",
      "Epoch 639/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5180 - accuracy: 0.7097 - val_loss: 2.4272 - val_accuracy: 0.4887\n",
      "Epoch 640/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5188 - accuracy: 0.7102 - val_loss: 2.2755 - val_accuracy: 0.4974\n",
      "Epoch 641/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5167 - accuracy: 0.7106 - val_loss: 2.3208 - val_accuracy: 0.4993\n",
      "Epoch 642/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5161 - accuracy: 0.7132 - val_loss: 2.3362 - val_accuracy: 0.5166\n",
      "Epoch 643/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5172 - accuracy: 0.7125 - val_loss: 2.3492 - val_accuracy: 0.5361\n",
      "Epoch 644/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5183 - accuracy: 0.7098 - val_loss: 2.6322 - val_accuracy: 0.5011\n",
      "Epoch 645/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5157 - accuracy: 0.7110 - val_loss: 2.3928 - val_accuracy: 0.5183\n",
      "Epoch 646/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5177 - accuracy: 0.7088 - val_loss: 2.4510 - val_accuracy: 0.4954\n",
      "Epoch 647/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7084 - val_loss: 2.3909 - val_accuracy: 0.5179\n",
      "Epoch 648/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5170 - accuracy: 0.7099 - val_loss: 2.3704 - val_accuracy: 0.4983\n",
      "Epoch 649/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5167 - accuracy: 0.7079 - val_loss: 2.3249 - val_accuracy: 0.5300\n",
      "Epoch 650/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5183 - accuracy: 0.7100 - val_loss: 2.4307 - val_accuracy: 0.5301\n",
      "Epoch 651/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5174 - accuracy: 0.7080 - val_loss: 2.4510 - val_accuracy: 0.5422\n",
      "Epoch 652/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5170 - accuracy: 0.7091 - val_loss: 2.5229 - val_accuracy: 0.5449\n",
      "Epoch 653/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5172 - accuracy: 0.7094 - val_loss: 2.3707 - val_accuracy: 0.5135\n",
      "Epoch 654/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7101 - val_loss: 2.3887 - val_accuracy: 0.4957\n",
      "Epoch 655/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5197 - accuracy: 0.7079 - val_loss: 2.4511 - val_accuracy: 0.5113\n",
      "Epoch 656/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5157 - accuracy: 0.7095 - val_loss: 2.5471 - val_accuracy: 0.5107\n",
      "Epoch 657/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5197 - accuracy: 0.7087 - val_loss: 2.4071 - val_accuracy: 0.4956\n",
      "Epoch 658/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5195 - accuracy: 0.7105 - val_loss: 2.4942 - val_accuracy: 0.5163\n",
      "Epoch 659/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7105 - val_loss: 2.3883 - val_accuracy: 0.5292\n",
      "Epoch 660/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5166 - accuracy: 0.7097 - val_loss: 2.4389 - val_accuracy: 0.5137\n",
      "Epoch 661/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5155 - accuracy: 0.7089 - val_loss: 2.4631 - val_accuracy: 0.5422\n",
      "Epoch 662/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5178 - accuracy: 0.7082 - val_loss: 2.4376 - val_accuracy: 0.5255\n",
      "Epoch 663/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5179 - accuracy: 0.7095 - val_loss: 2.3372 - val_accuracy: 0.5242\n",
      "Epoch 664/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5203 - accuracy: 0.7106 - val_loss: 2.3137 - val_accuracy: 0.5446\n",
      "Epoch 665/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7107 - val_loss: 2.4189 - val_accuracy: 0.5107\n",
      "Epoch 666/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5161 - accuracy: 0.7098 - val_loss: 2.4042 - val_accuracy: 0.5198\n",
      "Epoch 667/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5161 - accuracy: 0.7115 - val_loss: 2.4435 - val_accuracy: 0.5004\n",
      "Epoch 668/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.7105 - val_loss: 2.4157 - val_accuracy: 0.5107\n",
      "Epoch 669/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5172 - accuracy: 0.7109 - val_loss: 2.5559 - val_accuracy: 0.5207\n",
      "Epoch 670/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5136 - accuracy: 0.7115 - val_loss: 2.5702 - val_accuracy: 0.5268\n",
      "Epoch 671/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5171 - accuracy: 0.7090 - val_loss: 2.5920 - val_accuracy: 0.5202\n",
      "Epoch 672/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5168 - accuracy: 0.7093 - val_loss: 2.2955 - val_accuracy: 0.4987\n",
      "Epoch 673/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5153 - accuracy: 0.7101 - val_loss: 2.4607 - val_accuracy: 0.5327\n",
      "Epoch 674/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5179 - accuracy: 0.7095 - val_loss: 2.3880 - val_accuracy: 0.5152\n",
      "Epoch 675/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5140 - accuracy: 0.7111 - val_loss: 2.4754 - val_accuracy: 0.5000\n",
      "Epoch 676/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5159 - accuracy: 0.7094 - val_loss: 2.5124 - val_accuracy: 0.4815\n",
      "Epoch 677/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7117 - val_loss: 2.3855 - val_accuracy: 0.4937\n",
      "Epoch 678/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5161 - accuracy: 0.7117 - val_loss: 2.3690 - val_accuracy: 0.4970\n",
      "Epoch 679/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5150 - accuracy: 0.7111 - val_loss: 2.2572 - val_accuracy: 0.5078\n",
      "Epoch 680/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5179 - accuracy: 0.7113 - val_loss: 2.5179 - val_accuracy: 0.5239\n",
      "Epoch 681/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5147 - accuracy: 0.7100 - val_loss: 2.4500 - val_accuracy: 0.5109\n",
      "Epoch 682/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7110 - val_loss: 2.4060 - val_accuracy: 0.5202\n",
      "Epoch 683/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5150 - accuracy: 0.7099 - val_loss: 2.5404 - val_accuracy: 0.5385\n",
      "Epoch 684/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5211 - accuracy: 0.7071 - val_loss: 2.4311 - val_accuracy: 0.5220\n",
      "Epoch 685/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5136 - accuracy: 0.7106 - val_loss: 2.4755 - val_accuracy: 0.5277\n",
      "Epoch 686/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5161 - accuracy: 0.7102 - val_loss: 2.4267 - val_accuracy: 0.5166\n",
      "Epoch 687/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5159 - accuracy: 0.7118 - val_loss: 2.7129 - val_accuracy: 0.5351\n",
      "Epoch 688/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5167 - accuracy: 0.7107 - val_loss: 2.5210 - val_accuracy: 0.5096\n",
      "Epoch 689/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5124 - accuracy: 0.7114 - val_loss: 2.5276 - val_accuracy: 0.5218\n",
      "Epoch 690/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5143 - accuracy: 0.7104 - val_loss: 2.5737 - val_accuracy: 0.5113\n",
      "Epoch 691/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5170 - accuracy: 0.7083 - val_loss: 2.6202 - val_accuracy: 0.5039\n",
      "Epoch 692/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7098 - val_loss: 2.6123 - val_accuracy: 0.5370\n",
      "Epoch 693/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5155 - accuracy: 0.7121 - val_loss: 2.4093 - val_accuracy: 0.5178\n",
      "Epoch 694/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7122 - val_loss: 2.4683 - val_accuracy: 0.4939\n",
      "Epoch 695/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5156 - accuracy: 0.7091 - val_loss: 2.4483 - val_accuracy: 0.5098\n",
      "Epoch 696/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5137 - accuracy: 0.7125 - val_loss: 2.5645 - val_accuracy: 0.5083\n",
      "Epoch 697/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5161 - accuracy: 0.7102 - val_loss: 2.6004 - val_accuracy: 0.5353\n",
      "Epoch 698/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.7114 - val_loss: 2.3635 - val_accuracy: 0.5457\n",
      "Epoch 699/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5163 - accuracy: 0.7095 - val_loss: 2.4321 - val_accuracy: 0.5142\n",
      "Epoch 700/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5154 - accuracy: 0.7112 - val_loss: 2.5822 - val_accuracy: 0.5453\n",
      "Epoch 701/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7125 - val_loss: 2.5189 - val_accuracy: 0.5172\n",
      "Epoch 702/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.7106 - val_loss: 2.5838 - val_accuracy: 0.5357\n",
      "Epoch 703/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5162 - accuracy: 0.7117 - val_loss: 2.4719 - val_accuracy: 0.5233\n",
      "Epoch 704/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5163 - accuracy: 0.7102 - val_loss: 2.4709 - val_accuracy: 0.5141\n",
      "Epoch 705/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5136 - accuracy: 0.7130 - val_loss: 2.5861 - val_accuracy: 0.5386\n",
      "Epoch 706/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5147 - accuracy: 0.7116 - val_loss: 2.3926 - val_accuracy: 0.5131\n",
      "Epoch 707/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7089 - val_loss: 2.4238 - val_accuracy: 0.5092\n",
      "Epoch 708/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7101 - val_loss: 2.5852 - val_accuracy: 0.4898\n",
      "Epoch 709/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7072 - val_loss: 2.3893 - val_accuracy: 0.4893\n",
      "Epoch 710/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7115 - val_loss: 2.5297 - val_accuracy: 0.5503\n",
      "Epoch 711/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5155 - accuracy: 0.7094 - val_loss: 2.6213 - val_accuracy: 0.5065\n",
      "Epoch 712/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5153 - accuracy: 0.7096 - val_loss: 2.4181 - val_accuracy: 0.5133\n",
      "Epoch 713/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5165 - accuracy: 0.7089 - val_loss: 2.4741 - val_accuracy: 0.5057\n",
      "Epoch 714/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7104 - val_loss: 2.5798 - val_accuracy: 0.5192\n",
      "Epoch 715/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7105 - val_loss: 2.6414 - val_accuracy: 0.5340\n",
      "Epoch 716/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5147 - accuracy: 0.7108 - val_loss: 2.6147 - val_accuracy: 0.5283\n",
      "Epoch 717/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7115 - val_loss: 2.4434 - val_accuracy: 0.5821\n",
      "Epoch 718/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5158 - accuracy: 0.7116 - val_loss: 2.5424 - val_accuracy: 0.5113\n",
      "Epoch 719/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5153 - accuracy: 0.7122 - val_loss: 2.4551 - val_accuracy: 0.4885\n",
      "Epoch 720/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7097 - val_loss: 2.5776 - val_accuracy: 0.5214\n",
      "Epoch 721/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7121 - val_loss: 2.5708 - val_accuracy: 0.5129\n",
      "Epoch 722/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5151 - accuracy: 0.7134 - val_loss: 2.4698 - val_accuracy: 0.5037\n",
      "Epoch 723/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5130 - accuracy: 0.7137 - val_loss: 2.5159 - val_accuracy: 0.5189\n",
      "Epoch 724/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5139 - accuracy: 0.7119 - val_loss: 2.5249 - val_accuracy: 0.5011\n",
      "Epoch 725/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5162 - accuracy: 0.7120 - val_loss: 2.5885 - val_accuracy: 0.5396\n",
      "Epoch 726/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5138 - accuracy: 0.7131 - val_loss: 2.5174 - val_accuracy: 0.5035\n",
      "Epoch 727/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5140 - accuracy: 0.7108 - val_loss: 2.5851 - val_accuracy: 0.5059\n",
      "Epoch 728/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7121 - val_loss: 2.6457 - val_accuracy: 0.5063\n",
      "Epoch 729/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5158 - accuracy: 0.7080 - val_loss: 2.5767 - val_accuracy: 0.5255\n",
      "Epoch 730/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5177 - accuracy: 0.7111 - val_loss: 2.6028 - val_accuracy: 0.5433\n",
      "Epoch 731/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5149 - accuracy: 0.7112 - val_loss: 2.5568 - val_accuracy: 0.5227\n",
      "Epoch 732/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5142 - accuracy: 0.7107 - val_loss: 2.5177 - val_accuracy: 0.5327\n",
      "Epoch 733/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7109 - val_loss: 2.4187 - val_accuracy: 0.5165\n",
      "Epoch 734/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5136 - accuracy: 0.7118 - val_loss: 2.5135 - val_accuracy: 0.4924\n",
      "Epoch 735/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5122 - accuracy: 0.7121 - val_loss: 2.5765 - val_accuracy: 0.5022\n",
      "Epoch 736/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5133 - accuracy: 0.7102 - val_loss: 2.5625 - val_accuracy: 0.5189\n",
      "Epoch 737/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5127 - accuracy: 0.7126 - val_loss: 2.6423 - val_accuracy: 0.5007\n",
      "Epoch 738/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5163 - accuracy: 0.7114 - val_loss: 2.6123 - val_accuracy: 0.5172\n",
      "Epoch 739/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5108 - accuracy: 0.7140 - val_loss: 2.6375 - val_accuracy: 0.4880\n",
      "Epoch 740/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7118 - val_loss: 2.7094 - val_accuracy: 0.5301\n",
      "Epoch 741/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7132 - val_loss: 2.5112 - val_accuracy: 0.4930\n",
      "Epoch 742/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5142 - accuracy: 0.7130 - val_loss: 2.5926 - val_accuracy: 0.5342\n",
      "Epoch 743/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5162 - accuracy: 0.7110 - val_loss: 2.5071 - val_accuracy: 0.5174\n",
      "Epoch 744/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7128 - val_loss: 2.5937 - val_accuracy: 0.5131\n",
      "Epoch 745/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5129 - accuracy: 0.7089 - val_loss: 2.5983 - val_accuracy: 0.5044\n",
      "Epoch 746/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5158 - accuracy: 0.7117 - val_loss: 2.4435 - val_accuracy: 0.5178\n",
      "Epoch 747/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5150 - accuracy: 0.7110 - val_loss: 2.4189 - val_accuracy: 0.5211\n",
      "Epoch 748/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7123 - val_loss: 2.6057 - val_accuracy: 0.4987\n",
      "Epoch 749/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7111 - val_loss: 2.5467 - val_accuracy: 0.5438\n",
      "Epoch 750/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5141 - accuracy: 0.7129 - val_loss: 2.5202 - val_accuracy: 0.5320\n",
      "Epoch 751/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5132 - accuracy: 0.7132 - val_loss: 2.5502 - val_accuracy: 0.5041\n",
      "Epoch 752/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5127 - accuracy: 0.7137 - val_loss: 2.5772 - val_accuracy: 0.5083\n",
      "Epoch 753/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5127 - accuracy: 0.7132 - val_loss: 2.5615 - val_accuracy: 0.4911\n",
      "Epoch 754/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7128 - val_loss: 2.5957 - val_accuracy: 0.5063\n",
      "Epoch 755/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5137 - accuracy: 0.7111 - val_loss: 2.7000 - val_accuracy: 0.5459\n",
      "Epoch 756/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5153 - accuracy: 0.7109 - val_loss: 2.6824 - val_accuracy: 0.5131\n",
      "Epoch 757/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7127 - val_loss: 2.6611 - val_accuracy: 0.5344\n",
      "Epoch 758/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5124 - accuracy: 0.7144 - val_loss: 2.6929 - val_accuracy: 0.5272\n",
      "Epoch 759/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7118 - val_loss: 2.6937 - val_accuracy: 0.5497\n",
      "Epoch 760/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5145 - accuracy: 0.7101 - val_loss: 2.7810 - val_accuracy: 0.5401\n",
      "Epoch 761/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5136 - accuracy: 0.7121 - val_loss: 2.6424 - val_accuracy: 0.5046\n",
      "Epoch 762/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5125 - accuracy: 0.7113 - val_loss: 2.7543 - val_accuracy: 0.5488\n",
      "Epoch 763/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5134 - accuracy: 0.7115 - val_loss: 2.6393 - val_accuracy: 0.5599\n",
      "Epoch 764/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5155 - accuracy: 0.7120 - val_loss: 2.6599 - val_accuracy: 0.5126\n",
      "Epoch 765/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5109 - accuracy: 0.7122 - val_loss: 2.6368 - val_accuracy: 0.5335\n",
      "Epoch 766/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5151 - accuracy: 0.7124 - val_loss: 2.6007 - val_accuracy: 0.5224\n",
      "Epoch 767/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5111 - accuracy: 0.7138 - val_loss: 2.6542 - val_accuracy: 0.5161\n",
      "Epoch 768/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5174 - accuracy: 0.7089 - val_loss: 2.6574 - val_accuracy: 0.5216\n",
      "Epoch 769/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5125 - accuracy: 0.7110 - val_loss: 2.7463 - val_accuracy: 0.5200\n",
      "Epoch 770/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5125 - accuracy: 0.7138 - val_loss: 2.7242 - val_accuracy: 0.5113\n",
      "Epoch 771/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5139 - accuracy: 0.7110 - val_loss: 2.5479 - val_accuracy: 0.5438\n",
      "Epoch 772/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5122 - accuracy: 0.7124 - val_loss: 2.8451 - val_accuracy: 0.5405\n",
      "Epoch 773/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5129 - accuracy: 0.7125 - val_loss: 2.6598 - val_accuracy: 0.5161\n",
      "Epoch 774/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7147 - val_loss: 2.5037 - val_accuracy: 0.5063\n",
      "Epoch 775/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5110 - accuracy: 0.7144 - val_loss: 2.6047 - val_accuracy: 0.5312\n",
      "Epoch 776/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5133 - accuracy: 0.7123 - val_loss: 2.5734 - val_accuracy: 0.5102\n",
      "Epoch 777/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7128 - val_loss: 2.5540 - val_accuracy: 0.5214\n",
      "Epoch 778/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5112 - accuracy: 0.7124 - val_loss: 2.7642 - val_accuracy: 0.5122\n",
      "Epoch 779/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5141 - accuracy: 0.7116 - val_loss: 2.2733 - val_accuracy: 0.5170\n",
      "Epoch 780/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5135 - accuracy: 0.7128 - val_loss: 2.5536 - val_accuracy: 0.5224\n",
      "Epoch 781/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5141 - accuracy: 0.7119 - val_loss: 2.7173 - val_accuracy: 0.5109\n",
      "Epoch 782/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5097 - accuracy: 0.7131 - val_loss: 2.6647 - val_accuracy: 0.5129\n",
      "Epoch 783/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7106 - val_loss: 2.6289 - val_accuracy: 0.5370\n",
      "Epoch 784/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5105 - accuracy: 0.7109 - val_loss: 2.4949 - val_accuracy: 0.5214\n",
      "Epoch 785/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7139 - val_loss: 2.6927 - val_accuracy: 0.5385\n",
      "Epoch 786/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5126 - accuracy: 0.7130 - val_loss: 2.7094 - val_accuracy: 0.5094\n",
      "Epoch 787/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5162 - accuracy: 0.7091 - val_loss: 2.6710 - val_accuracy: 0.5094\n",
      "Epoch 788/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5106 - accuracy: 0.7142 - val_loss: 2.7244 - val_accuracy: 0.5244\n",
      "Epoch 789/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5126 - accuracy: 0.7133 - val_loss: 2.6695 - val_accuracy: 0.5255\n",
      "Epoch 790/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7114 - val_loss: 2.6565 - val_accuracy: 0.5288\n",
      "Epoch 791/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5112 - accuracy: 0.7122 - val_loss: 2.6120 - val_accuracy: 0.5200\n",
      "Epoch 792/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5150 - accuracy: 0.7125 - val_loss: 2.6635 - val_accuracy: 0.5342\n",
      "Epoch 793/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5102 - accuracy: 0.7129 - val_loss: 2.7001 - val_accuracy: 0.5011\n",
      "Epoch 794/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5118 - accuracy: 0.7131 - val_loss: 2.6425 - val_accuracy: 0.5020\n",
      "Epoch 795/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5127 - accuracy: 0.7128 - val_loss: 2.9295 - val_accuracy: 0.5181\n",
      "Epoch 796/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5107 - accuracy: 0.7122 - val_loss: 2.5529 - val_accuracy: 0.5111\n",
      "Epoch 797/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5111 - accuracy: 0.7130 - val_loss: 2.6484 - val_accuracy: 0.5146\n",
      "Epoch 798/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5121 - accuracy: 0.7126 - val_loss: 2.7975 - val_accuracy: 0.5061\n",
      "Epoch 799/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5101 - accuracy: 0.7143 - val_loss: 2.6594 - val_accuracy: 0.5444\n",
      "Epoch 800/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7138 - val_loss: 2.6684 - val_accuracy: 0.5165\n",
      "Epoch 801/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5112 - accuracy: 0.7137 - val_loss: 2.7143 - val_accuracy: 0.5080\n",
      "Epoch 802/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7145 - val_loss: 2.5661 - val_accuracy: 0.5018\n",
      "Epoch 803/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5125 - accuracy: 0.7131 - val_loss: 2.6786 - val_accuracy: 0.5447\n",
      "Epoch 804/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5128 - accuracy: 0.7124 - val_loss: 2.6131 - val_accuracy: 0.5545\n",
      "Epoch 805/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7136 - val_loss: 2.7075 - val_accuracy: 0.5153\n",
      "Epoch 806/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5119 - accuracy: 0.7128 - val_loss: 2.6707 - val_accuracy: 0.5022\n",
      "Epoch 807/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5123 - accuracy: 0.7123 - val_loss: 2.5839 - val_accuracy: 0.5174\n",
      "Epoch 808/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5084 - accuracy: 0.7142 - val_loss: 2.7057 - val_accuracy: 0.5298\n",
      "Epoch 809/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7125 - val_loss: 2.7737 - val_accuracy: 0.5131\n",
      "Epoch 810/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5144 - accuracy: 0.7116 - val_loss: 2.7020 - val_accuracy: 0.5385\n",
      "Epoch 811/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5104 - accuracy: 0.7132 - val_loss: 2.5935 - val_accuracy: 0.4954\n",
      "Epoch 812/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5130 - accuracy: 0.7123 - val_loss: 2.6482 - val_accuracy: 0.5163\n",
      "Epoch 813/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5105 - accuracy: 0.7131 - val_loss: 2.7778 - val_accuracy: 0.5250\n",
      "Epoch 814/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5129 - accuracy: 0.7117 - val_loss: 2.5870 - val_accuracy: 0.5257\n",
      "Epoch 815/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5119 - accuracy: 0.7128 - val_loss: 2.7302 - val_accuracy: 0.5394\n",
      "Epoch 816/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5117 - accuracy: 0.7139 - val_loss: 2.8085 - val_accuracy: 0.5394\n",
      "Epoch 817/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5115 - accuracy: 0.7115 - val_loss: 2.6746 - val_accuracy: 0.5146\n",
      "Epoch 818/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5113 - accuracy: 0.7120 - val_loss: 2.7182 - val_accuracy: 0.5163\n",
      "Epoch 819/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5117 - accuracy: 0.7113 - val_loss: 2.7301 - val_accuracy: 0.5054\n",
      "Epoch 820/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.7120 - val_loss: 2.9028 - val_accuracy: 0.5320\n",
      "Epoch 821/5000\n",
      "1028/1028 [==============================] - 1s 1ms/step - loss: 0.5119 - accuracy: 0.7124 - val_loss: 2.7400 - val_accuracy: 0.5124\n",
      "Epoch 822/5000\n",
      "1019/1028 [============================>.] - ETA: 0s - loss: 0.5090 - accuracy: 0.7151"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/allah/freqtrade/json_dict/2_labels.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c696e6f64655f746f6b796f5f31227d/allah/freqtrade/json_dict/2_labels.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c696e6f64655f746f6b796f5f31227d/allah/freqtrade/json_dict/2_labels.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m tensorboard \u001b[39m=\u001b[39m TensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./logs\u001b[39m\u001b[39m'\u001b[39m, histogram_freq\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, write_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, write_images\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c696e6f64655f746f6b796f5f31227d/allah/freqtrade/json_dict/2_labels.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_resampled, y_train_resampled, epochs\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test_scaled, y_test), callbacks\u001b[39m=\u001b[39;49m[])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c696e6f64655f746f6b796f5f31227d/allah/freqtrade/json_dict/2_labels.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Step 6: Evaluate the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224c696e6f64655f746f6b796f5f31227d/allah/freqtrade/json_dict/2_labels.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test_scaled, y_test)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/keras/src/engine/training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1777\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1778\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         pss_evaluation_shards\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[0;32m-> 1791\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1792\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1793\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1794\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1795\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1796\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1797\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1798\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1799\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1800\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1801\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1802\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1803\u001b[0m )\n\u001b[1;32m   1804\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1806\u001b[0m }\n\u001b[1;32m   1807\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/keras/src/engine/training.py:2200\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2197\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2198\u001b[0m             ):\n\u001b[1;32m   2199\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2200\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2201\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2202\u001b[0m                     data_handler,\n\u001b[1;32m   2203\u001b[0m                     step,\n\u001b[1;32m   2204\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2205\u001b[0m                 )\n\u001b[1;32m   2207\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2208\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/keras/src/engine/training.py:4000\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4000\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4001\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4002\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    862\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    865\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    866\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:147\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m--> 147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:359\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m current_func_context \u001b[39m=\u001b[39m function_context\u001b[39m.\u001b[39mmake_function_context()\n\u001b[1;32m    355\u001b[0m \u001b[39m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[39m# only active captures should be saved.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m lookup_func_type, lookup_func_context \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 359\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_spec\u001b[39m.\u001b[39;49mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    360\u001b[0m         args, kwargs, captures))\n\u001b[1;32m    361\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mlookup(current_func_context,\n\u001b[1;32m    362\u001b[0m                                                 lookup_func_type)\n\u001b[1;32m    363\u001b[0m \u001b[39mif\u001b[39;00m concrete_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:324\u001b[0m, in \u001b[0;36mFunctionSpec.make_canonicalized_monomorphic_type\u001b[0;34m(self, args, kwargs, captures)\u001b[0m\n\u001b[1;32m    316\u001b[0m   captures \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    318\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    319\u001b[0m     function_type_lib\u001b[39m.\u001b[39msanitize_arg_name(name): value\n\u001b[1;32m    320\u001b[0m     \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    321\u001b[0m }\n\u001b[1;32m    323\u001b[0m _, function_type, type_context \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 324\u001b[0m     function_type_lib\u001b[39m.\u001b[39;49mcanonicalize_to_monomorphic(\n\u001b[1;32m    325\u001b[0m         args, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault_values, captures, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[39mreturn\u001b[39;00m function_type, type_context\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:462\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, captures, polymorphic_type)\u001b[0m\n\u001b[1;32m    456\u001b[0m       parameters\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    457\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[1;32m    458\u001b[0m                                      Parameter\u001b[39m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[1;32m    459\u001b[0m                                      poly_parameter\u001b[39m.\u001b[39mtype_constraint))\n\u001b[1;32m    460\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     parameters\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 462\u001b[0m         _make_validated_mono_param(name, arg, poly_parameter\u001b[39m.\u001b[39;49mkind,\n\u001b[1;32m    463\u001b[0m                                    type_context,\n\u001b[1;32m    464\u001b[0m                                    poly_parameter\u001b[39m.\u001b[39;49mtype_constraint))\n\u001b[1;32m    466\u001b[0m capture_types \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mOrderedDict()\n\u001b[1;32m    467\u001b[0m \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m captures\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/allah/freqtrade/.env/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:398\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    397\u001b[0m \u001b[39m# TODO(fmuham): Consider forcing kind to be always POSITIONAL_OR_KEYWORD.\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_validated_mono_param\u001b[39m(\n\u001b[1;32m    399\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[1;32m    400\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Parameter:\n\u001b[1;32m    401\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m   mono_type \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mfrom_value(value, type_context)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "# Assuming you have already loaded your data\n",
    "df_long = df_combined[(df_combined.label == 'true_long') | (df_combined.label == 'false_long')]\n",
    "# Step 1: Select features and target variable\n",
    "features = lag_columns\n",
    "target = 'label'\n",
    "\n",
    "# Encode the labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_df = df_long[df_long.trade == 1.0]\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df[features], train_df[target], test_size=0.2,shuffle=False, random_state=42\n",
    ")\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     train_df[features], train_df[target], test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# Step 3: Scale the features (MinMaxScaler)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Count the number of samples in each class\n",
    "print(\"Class distribution before oversampling:\", Counter(y_train))\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count the number of samples in each class after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y_train_resampled))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "# Step 4: Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(60, input_dim=len(features), activation='relu'),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(3, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification, so use 'sigmoid' activation\n",
    "])\n",
    "\n",
    "# Specify a higher learning rate for the Adam optimizer\n",
    "learning_rate = 0.001  # You can adjust this value\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model with the specified optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model with TensorBoard\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
    "model.fit(X_train_resampled, y_train_resampled, epochs=5000, batch_size=32, validation_data=(X_test_scaled, y_test), callbacks=[])\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Inverse transform the encoded labels to get the original labels\n",
    "# original_labels = label_encoder.inverse_transform(model.predict(X_test_scaled) > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have already loaded your data\n",
    "# df_long = df_combined[(df_combined.label == 'true_long') | (df_combined.label == 'false_long')]\n",
    "\n",
    "# Step 1: Select features and target variable\n",
    "features = lag_columns\n",
    "target = 'label'\n",
    "\n",
    "# Encode the labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# train_df = df_long[df_long.trade == 1.0]\n",
    "# Assuming you have already loaded your data and encoded labels\n",
    "# train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "X_train, y_train, X_test, y_test = np.random.rand(100, len(features)), np.random.randint(0, 2, 100), np.random.rand(20, len(features)), np.random.randint(0, 2, 20)\n",
    "\n",
    "# Step 2: Scale the features (MinMaxScaler)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Count the number of samples in each class\n",
    "print(\"Class distribution before oversampling:\", Counter(y_train))\n",
    "\n",
    "# Apply SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Count the number of samples in each class after oversampling\n",
    "print(\"Class distribution after oversampling:\", Counter(y_train_resampled))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Step 3: Define a simple neural network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def initialize_params(self, num_features):\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sigmoid(np.dot(X, self.weights) + self.bias)\n",
    "\n",
    "    def compute_loss(self, y, y_pred):\n",
    "        m = len(y)\n",
    "        return -1/m * np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "\n",
    "    def fit(self, X, y, learning_rate, num_epochs):\n",
    "        m, num_features = X.shape\n",
    "        self.initialize_params(num_features)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            y_pred = self.forward(X)\n",
    "\n",
    "            dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1/m) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights -= learning_rate * dw\n",
    "            self.bias -= learning_rate * db\n",
    "\n",
    "            loss = self.compute_loss(y, y_pred)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.forward(X)\n",
    "        return (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Step 4: Train the simple neural network\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5000\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.fit(X_train_resampled, y_train_resampled, learning_rate, num_epochs)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "accuracy = np.mean(y_pred_test == y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
